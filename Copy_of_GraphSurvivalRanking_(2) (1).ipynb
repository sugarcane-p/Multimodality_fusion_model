{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHvq4FDiYoe"
      },
      "source": [
        "If running on Google Colab uncomment here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxpXL3w8yjCJ",
        "outputId": "d5761514-040f-4ef0-abf5-4de83d3937f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MDvz0BOxTBZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334648fd-3689-47d6-867a-9d05ab4f8937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.2.0%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (884 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m884.9/884.9 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.2.0+pt20cu118 torch_cluster-1.6.1+pt20cu118 torch_scatter-2.1.1+pt20cu118 torch_sparse-0.6.17+pt20cu118 torch_spline_conv-1.2.2+pt20cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=0fdc3e425650515ca7afa2c72b70a2dee5d243fd28fa6161eefc2f2e693d4fcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n",
            "Collecting lifelines\n",
            "  Downloading lifelines-0.27.7-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.6.2)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-0.6.4-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.5->lifelines) (0.18.3)\n",
            "Collecting astor>=0.8 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->lifelines) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=48b9ed39185c6adf057d7a09c2e2d6548a3b54b9fa780e8234895becd76397f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, astor, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed astor-0.8.1 autograd-gamma-0.5.0 formulaic-0.6.4 interface-meta-1.3.0 lifelines-0.27.7\n"
          ]
        }
      ],
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
        "!pip install torch-geometric\n",
        "!pip install lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "vcyDY-9vTjmP"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "from torch.utils.data import Dataset, Sampler\n",
        "import torch.utils.data as data_utils\n",
        "from torchvision import datasets, transforms\n",
        "from copy import deepcopy\n",
        "from numpy.random import randn\n",
        "from torch.nn import BatchNorm1d\n",
        "from torch.nn import Sequential, Linear, ReLU,Tanh,LeakyReLU,ELU,SELU,GELU\n",
        "from torch_geometric.nn import GINConv,GATConv,EdgeConv, PNAConv,DynamicEdgeConv,global_add_pool, global_mean_pool, global_max_pool\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial import distance_matrix, Delaunay\n",
        "import random\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "import pickle\n",
        "from glob import glob\n",
        "import os\n",
        "from sklearn.neighbors import kneighbors_graph, radius_neighbors_graph\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pdb\n",
        "from statistics import mean, stdev\n",
        "from glob import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from torch.autograd import Variable\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.neighbors import kneighbors_graph, radius_neighbors_graph\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import math\n",
        "from random import shuffle\n",
        "from itertools import islice\n",
        "from lifelines.utils import concordance_index as cindex\n",
        "from lifelines import KaplanMeierFitter\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.init import xavier_normal_\n",
        "import operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS_LOUYVTjmQ"
      },
      "source": [
        "Set up the variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HhTBT3MmTjmQ"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.00001\n",
        "WEIGHT_DECAY = 0.0002\n",
        "L1_WEIGHT = 0.001\n",
        "SCHEDULER = None\n",
        "BATCH_SIZE = 10\n",
        "NUM_BATCHES = 2000\n",
        "NUM_LOGS = 150 # How many times in training the loss value is stored\n",
        "\n",
        "#Select what feature set to use\n",
        "SHUFFLE_NET = True\n",
        "\n",
        "VALIDATION = True\n",
        "NORMALIZE = False\n",
        "CENSORING = True\n",
        "FRAC_TRAIN = 0.8\n",
        "CONCORD_TRACK = True\n",
        "FILTER_TRIPLE = False\n",
        "EARLY_STOPPING = True\n",
        "MODEL_PATH = 'Best_model/'\n",
        "VARIABLES = 'DSS'\n",
        "TIME_VAR = VARIABLES + '.time'\n",
        "ON_GPU = True\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "rng = np.random.default_rng()\n",
        "device = {True:'cuda:0',False:'cpu'}[USE_CUDA]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLPofWzeTjmR"
      },
      "source": [
        "Accessory methods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mAl4eI-RTjmR"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cuda(v):\n",
        "    if USE_CUDA:\n",
        "        return v.cuda()\n",
        "    return v\n",
        "\n",
        "def toTensor(v,dtype = torch.float,requires_grad = True):\n",
        "    return torch.from_numpy(np.array(v)).type(dtype).requires_grad_(requires_grad)\n",
        "\n",
        "def toTensorGPU(v,dtype = torch.float,requires_grad = True):\n",
        "    return cuda(torch.from_numpy(np.array(v)).type(dtype).requires_grad_(requires_grad))\n",
        "\n",
        "def toNumpy(v):\n",
        "    if type(v) is not torch.Tensor: return np.asarray(v)\n",
        "    if USE_CUDA:\n",
        "        return v.detach().cpu().numpy()\n",
        "    return v.detach().numpy()\n",
        "\n",
        "def pickleLoad(ifile):\n",
        "    with open(ifile, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def toGeometric(Gb,y,tt=1e-3):\n",
        "    return Data(x=Gb.x, edge_index=(Gb.get(W)>tt).nonzero().t().contiguous(),y=y)\n",
        "\n",
        "def toGeometricWW(X,W,y,tt=0):\n",
        "    return Data(x=toTensor(X,requires_grad = False), edge_index=(toTensor(W,requires_grad = False)>tt).nonzero().t().contiguous(),y=toTensor([y],dtype=torch.long,requires_grad = False))\n",
        "\n",
        "\n",
        "def pair_find(graphs,features):\n",
        "    indexes = []\n",
        "    for j in range(len(graphs)):\n",
        "        graph_j = graphs[j]\n",
        "        if features == 'BRCA-SHUFFLE':\n",
        "            event_j = graph_j[1][0]\n",
        "            time_j = graph_j[1][1]\n",
        "        else:\n",
        "            event_j, time_j = graph_j.event, graph_j.e_time\n",
        "        if event_j == 1:\n",
        "            for i in range(len(graphs)):\n",
        "                graph_i = graphs[i]\n",
        "                if features == 'BRCA-SHUFFLE':\n",
        "                    time_i = graph_i[1][1]\n",
        "                else:\n",
        "                    time_i = graph_i.e_time\n",
        "                if graph_j != graph_i and time_i > time_j:\n",
        "                    indexes.append((i,j))\n",
        "    shuffle(indexes)\n",
        "    return indexes\n",
        "\n",
        "\n",
        "def SplitBrcaData(dataset, numSplits, isShuffle, testSize):\n",
        "    if isShuffle:\n",
        "        eventVars = [dataset[i][1][0] for i in range(len(dataset))]\n",
        "    else:\n",
        "        eventVars = [int(dataset[i].event.detach().numpy()) for i in range(len(dataset))]\n",
        "    x = np.zeros(len(dataset))\n",
        "    shuffleSplit = StratifiedShuffleSplit(n_splits = numSplits, test_size = testSize, random_state=3)\n",
        "    return shuffleSplit.split(x,eventVars)\n",
        "\n",
        "def disk_graph_load(batch):\n",
        "    return [torch.load(directory + '/' + graph + '.g') for graph in batch]\n",
        "\n",
        "def get_predictions(model,graphs,model_indicator,features = 'BRCA-SHUFFLE',device=torch.device('cuda:0')) -> list:\n",
        "    outputs = []\n",
        "    e_and_t = []\n",
        "    model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(graphs)):\n",
        "            graph = graphs[i]\n",
        "            try:\n",
        "                gene_data = graphs[i][1][2]\n",
        "            except IndexError:\n",
        "                print(f\"IndexError encountered for i={i} (Testing)\")\n",
        "            if features == 'BRCA-SHUFFLE':\n",
        "                tag = [graph[0]]\n",
        "                temp = [graph[1][0], graph[1][1]]\n",
        "                graph = disk_graph_load(tag)\n",
        "            else:\n",
        "                temp = [graph.event.item(),graph.e_time.item()]\n",
        "                graph = [graph]\n",
        "            size = 1\n",
        "            loader = DataLoader(graph, batch_size=size)\n",
        "            for d in loader:\n",
        "                d = d.to(device)\n",
        "            if model_indicator == 'combine':\n",
        "                g_loader = DataLoader([gene_data], batch_size=size)\n",
        "                for g in g_loader:\n",
        "                    g = g.to(device)\n",
        "                z,_,_ = model(g,d)\n",
        "            else:\n",
        "                z,_,_ = model(d)\n",
        "            z = toNumpy(z)\n",
        "            outputs.append(z[0][0])\n",
        "            e_and_t.append(temp)\n",
        "    return outputs, e_and_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e6OOq8D3TjmR"
      },
      "outputs": [],
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, dim_features, dim_target, layers=[16,16,8],pooling='max',dropout = 0.0,conv='GINConv',gembed=False,**kwargs) -> None:\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        dim_features : TYPE Int\n",
        "            DESCRIPTION. Number of features of each node\n",
        "        dim_target : TYPE Int\n",
        "            DESCRIPTION. Number of outputs\n",
        "        layers : TYPE, optional List of number of nodes in each layer\n",
        "            DESCRIPTION. The default is [6,6].\n",
        "        pooling : TYPE, optional\n",
        "            DESCRIPTION. The default is 'max'.\n",
        "        dropout : TYPE, optional\n",
        "            DESCRIPTION. The default is 0.0.\n",
        "        conv : TYPE, optional Layer type string {'GINConv','EdgeConv'} supported\n",
        "            DESCRIPTION. The default is 'GINConv'.\n",
        "        gembed : TYPE, optional Graph Embedding\n",
        "            DESCRIPTION. The default is False. Pool node scores or pool node features\n",
        "        **kwargs : TYPE\n",
        "            DESCRIPTION.\n",
        "        Raises\n",
        "        ------\n",
        "        NotImplementedError\n",
        "            DESCRIPTION.\n",
        "        Returns\n",
        "        -------\n",
        "        None.\n",
        "        \"\"\"\n",
        "        super(GNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.embeddings_dim=layers\n",
        "        self.no_layers = len(self.embeddings_dim)\n",
        "        self.first_h = []\n",
        "        self.nns = []\n",
        "        self.convs = []\n",
        "        self.linears = []\n",
        "        self.pooling = {'max':global_max_pool,'mean':global_mean_pool,'add':global_add_pool}[pooling]\n",
        "        self.gembed = gembed #if True then learn graph embedding for final classification (classify pooled node features) otherwise pool node decision scores\n",
        "\n",
        "        for layer, out_emb_dim in enumerate(self.embeddings_dim):\n",
        "            if layer == 0:\n",
        "                self.first_h = Sequential(Linear(dim_features, out_emb_dim), BatchNorm1d(out_emb_dim),GELU())\n",
        "                self.linears.append(Sequential(Linear(out_emb_dim, dim_target),GELU()))\n",
        "\n",
        "            else:\n",
        "                input_emb_dim = self.embeddings_dim[layer-1]\n",
        "                self.linears.append(Linear(out_emb_dim, dim_target))\n",
        "                subnet = Sequential(Linear(input_emb_dim, out_emb_dim), BatchNorm1d(out_emb_dim))\n",
        "                if conv=='GINConv':\n",
        "                    self.nns.append(subnet)\n",
        "                    self.convs.append(GINConv(self.nns[-1], **kwargs))  # Eq. 4.2 eps=100, train_eps=False\n",
        "                elif conv=='EdgeConv':\n",
        "                    subnet = Sequential(Linear(2*input_emb_dim, out_emb_dim), BatchNorm1d(out_emb_dim))\n",
        "                    self.nns.append(subnet)\n",
        "                    self.convs.append(EdgeConv(self.nns[-1],**kwargs))#DynamicEdgeConv#EdgeConv                aggr='mean'\n",
        "                elif conv=='GATConv':\n",
        "                    self.nns.append(subnet)\n",
        "                    self.convs.append(GATConv(input_emb_dim, out_emb_dim, heads=8, concat=False, dropout=dropout))\n",
        "                else:\n",
        "                    raise NotImplementedError\n",
        "\n",
        "        self.nns = torch.nn.ModuleList(self.nns)\n",
        "        self.convs = torch.nn.ModuleList(self.convs)\n",
        "        self.linears = torch.nn.ModuleList(self.linears)  # has got one more for initial input\n",
        "\n",
        "    def forward(self, data) -> torch.tensor:\n",
        "\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        out = 0\n",
        "        pooling = self.pooling\n",
        "        Z = 0\n",
        "        for layer in range(self.no_layers):\n",
        "            if layer == 0:\n",
        "                x = self.first_h(x)\n",
        "                z = self.linears[layer](x)\n",
        "                Z+=z\n",
        "                dout = F.dropout(pooling(z, batch), p=self.dropout, training=self.training)\n",
        "                out += dout\n",
        "            else:\n",
        "                x = self.convs[layer-1](x,edge_index)\n",
        "                if not self.gembed:\n",
        "                    z = self.linears[layer](x)\n",
        "                    Z+=z\n",
        "                    dout = F.dropout(pooling(z, batch), p=self.dropout, training=self.training)\n",
        "                else:\n",
        "                    dout = F.dropout(self.linears[layer](pooling(x, batch)), p=self.dropout, training=self.training)\n",
        "                out += dout\n",
        "\n",
        "        return out,Z,x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BuFPWEwGOCK8"
      },
      "outputs": [],
      "source": [
        "class LinearSubNet(nn.Module):\n",
        "    def __init__(self, dim_features, hidden_dims, dropout=0.0, middle_layer=0, **kwargs) -> None:\n",
        "        super(LinearSubNet, self).__init__()\n",
        "\n",
        "        self.linears = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "        self.relus = nn.ModuleList()\n",
        "        self.dropouts = nn.ModuleList()\n",
        "\n",
        "        input_dim = dim_features\n",
        "        for hidden_dim in hidden_dims:\n",
        "            linear_layer = nn.Linear(input_dim, hidden_dim)\n",
        "            self.linears.append(linear_layer)\n",
        "\n",
        "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
        "            self.relus.append(nn.PReLU())\n",
        "            self.dropouts.append(nn.Dropout(dropout))\n",
        "            input_dim = hidden_dim\n",
        "\n",
        "        self.middle_layer = middle_layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        middle_output = None\n",
        "        output = x\n",
        "\n",
        "        for i in range(len(self.linears)):\n",
        "            output = self.linears[i](output)\n",
        "            output = self.batch_norms[i](output)\n",
        "            output = self.relus[i](output)\n",
        "            output = self.dropouts[i](output)\n",
        "\n",
        "            if i == self.middle_layer:\n",
        "                middle_output = output.clone()\n",
        "\n",
        "        return output, middle_output\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim, hidden_dims):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        input_size = input_dim\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(input_size, hidden_dim))\n",
        "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "            layers.append(nn.PReLU())\n",
        "            input_size = hidden_dim\n",
        "        layers.append(nn.Linear(input_size, encoding_dim))\n",
        "        self.encoder = nn.Sequential(*layers)\n",
        "\n",
        "        layers = []\n",
        "        input_size = encoding_dim\n",
        "        for hidden_dim in reversed(hidden_dims):\n",
        "            layers.append(nn.Linear(input_size, hidden_dim))\n",
        "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "            layers.append(nn.PReLU())\n",
        "            input_size = hidden_dim\n",
        "        layers.append(nn.Linear(input_size, input_dim))\n",
        "        self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "class GeneWithAE(nn.Module):\n",
        "    def __init__(self, ae_input_dim, gene_hidden, middle_layer):\n",
        "        super(GeneWithAE, self).__init__()\n",
        "\n",
        "        hidden_dims = [round(ae_input_dim * 0.75), round(ae_input_dim * 0.5)]\n",
        "        self.ae = Autoencoder(ae_input_dim, ae_input_dim // 2, hidden_dims)\n",
        "        self.gene = LinearSubNet(ae_input_dim // 2, gene_hidden, dropout=0.3, middle_layer=middle_layer)\n",
        "\n",
        "    def forward(self, data):\n",
        "        encoded, decoded = self.ae(data)\n",
        "        gene_output, middle_output = self.gene(encoded)\n",
        "        return gene_output, decoded, middle_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0lVN0RY4gzGy"
      },
      "outputs": [],
      "source": [
        "class LMF(nn.Module):\n",
        "    def __init__(self, gene_in, graph_in, hidden_dims, dropouts, output_dim, rank):\n",
        "\n",
        "        super(LMF, self).__init__()\n",
        "\n",
        "        self.gene_in = gene_in\n",
        "        self.graph_in = graph_in\n",
        "\n",
        "        self.gene_hidden = hidden_dims[0]\n",
        "        self.graph_hidden = hidden_dims[1]\n",
        "        self.output_dim = output_dim\n",
        "        self.rank = rank\n",
        "\n",
        "        self.gene_prob = dropouts[0]\n",
        "        self.graph_prob = dropouts[1]\n",
        "        self.post_fusion_prob = dropouts[2]\n",
        "\n",
        "        self.gene_subnet = GeneWithAE(self.gene_in, self.gene_hidden,0)\n",
        "        self.graph_subnet = GNN(dim_features=self.graph_in,\n",
        "                               dim_target = self.graph_hidden[-1], layers = self.graph_hidden[:-1], pooling = 'mean',\n",
        "                               dropout = 0.0, conv='EdgeConv', aggr = 'max')\n",
        "\n",
        "        self.post_fusion_dropout = nn.Dropout(p=self.post_fusion_prob)\n",
        "        self.gene_factor = Parameter(torch.Tensor(self.rank, self.gene_hidden[-1] + 1, self.output_dim))\n",
        "        self.graph_factor = Parameter(torch.Tensor(self.rank, self.graph_hidden[-1] + 1, self.output_dim))\n",
        "        self.fusion_weights = Parameter(torch.Tensor(1, self.rank))\n",
        "        self.fusion_bias = Parameter(torch.Tensor(1, self.output_dim))\n",
        "\n",
        "        # init teh factors\n",
        "        xavier_normal_(self.gene_factor)\n",
        "        xavier_normal_(self.graph_factor)\n",
        "        xavier_normal_(self.fusion_weights)\n",
        "        self.fusion_bias.data.fill_(0)\n",
        "        self.relu = nn.PReLU()\n",
        "\n",
        "    def forward(self, gene_x, graph_x):\n",
        "\n",
        "        gene_h,decoded_gene,_ = self.gene_subnet(gene_x)\n",
        "        graph_h, _,_ = self.graph_subnet(graph_x)\n",
        "        batch_size = gene_h.data.shape[0]\n",
        "\n",
        "        if gene_h.is_cuda:\n",
        "            DTYPE = torch.cuda.FloatTensor\n",
        "        else:\n",
        "            DTYPE = torch.FloatTensor\n",
        "\n",
        "        _gene_h = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), gene_h), dim=1)\n",
        "        _graph_h = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), graph_h), dim=1)\n",
        "\n",
        "        fusion_gene = torch.matmul(_gene_h, self.gene_factor)\n",
        "        fusion_graph = torch.matmul(_graph_h, self.graph_factor)\n",
        "        fusion_zy = fusion_gene * fusion_graph\n",
        "\n",
        "        output = torch.matmul(self.fusion_weights, fusion_zy.permute(1, 0, 2)).squeeze() + self.fusion_bias\n",
        "        output = output.view(-1, self.output_dim)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output, [decoded_gene],0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class second_fusion(nn.Module):\n",
        "    def __init__(self, gene_in, graph_in, hidden_dims, dropouts, LMF_output_dim, rank, middle_layers, share_hidden_dim):\n",
        "        super(second_fusion, self).__init__()\n",
        "\n",
        "        self.gene_in = gene_in\n",
        "        self.graph_in = graph_in\n",
        "\n",
        "        self.gene_middle = middle_layers[0]\n",
        "        self.graph_middle = middle_layers[1]\n",
        "\n",
        "        self.gene_hidden = hidden_dims[0]\n",
        "        self.graph_hidden = hidden_dims[1][:middle_layers[1]+1]\n",
        "        self.graph_encoder_hidden = hidden_dims[1][middle_layers[1]+1:]\n",
        "\n",
        "        self.share_hidden_dims = share_hidden_dim\n",
        "\n",
        "        self.output_dim = LMF_output_dim\n",
        "        self.rank = rank\n",
        "\n",
        "        self.gene_prob = dropouts[0]\n",
        "        self.graph_prob = dropouts[1]\n",
        "        self.post_fusion_prob = dropouts[2]\n",
        "\n",
        "        self.gene_subnet = GeneWithAE(self.gene_in,self.gene_hidden, self.gene_middle)\n",
        "        self.graph_subnet = GNN(dim_features=self.graph_in,\n",
        "                               dim_target = self.graph_hidden[-1], layers = self.graph_hidden[:-1],\n",
        "                               dropout = graph_prob, pooling = 'mean', conv='EdgeConv', aggr = 'max')\n",
        "        self.graph_encoder = Autoencoder(self.graph_hidden[-1],self.graph_encoder_hidden[-1],self.graph_encoder_hidden[0:-1])\n",
        "\n",
        "        self.gene_share_encoder = LinearSubNet(dim_features=self.gene_hidden[self.gene_middle], hidden_dims=self.share_hidden_dims,\n",
        "                                              dropout=self.gene_prob, middle_layer=0)\n",
        "        self.graph_share_encoder = LinearSubNet(dim_features=self.gene_hidden[self.gene_middle], hidden_dims=self.share_hidden_dims,\n",
        "                                              dropout=self.gene_prob, middle_layer=0)\n",
        "\n",
        "        self.post_fusion_dropout = nn.Dropout(p=self.post_fusion_prob)\n",
        "        self.gene_factor = Parameter(torch.Tensor(self.rank, self.share_hidden_dims[-1] + 1, self.output_dim))\n",
        "        self.graph_factor = Parameter(torch.Tensor(self.rank, self.share_hidden_dims[-1] + 1, self.output_dim))\n",
        "        self.fusion_weights = Parameter(torch.Tensor(1, self.rank))\n",
        "        self.fusion_bias = Parameter(torch.Tensor(1, self.output_dim))\n",
        "\n",
        "        # init teh factors\n",
        "        xavier_normal_(self.gene_factor)\n",
        "        xavier_normal_(self.graph_factor)\n",
        "        xavier_normal_(self.fusion_weights)\n",
        "        self.fusion_bias.data.fill_(0)\n",
        "\n",
        "        self.final_linear = nn.Linear(3, 1)\n",
        "        self.relu = nn.PReLU()\n",
        "\n",
        "    def forward(self, gene_x, graph_x):\n",
        "\n",
        "        gene_h,decoded_gene,middle_output_gene = self.gene_subnet(gene_x)\n",
        "        middle_output_graph, _,_ = self.graph_subnet(graph_x)\n",
        "        graph_h,decoded_graph = self.graph_encoder(middle_output_graph)\n",
        "        encoded_graph = middle_output_graph.clone()\n",
        "\n",
        "        middle_output_gene,_ = self.gene_share_encoder(middle_output_gene)\n",
        "        middle_output_graph,_ = self.graph_share_encoder(middle_output_graph)\n",
        "        batch_size = middle_output_graph.data.shape[0]\n",
        "\n",
        "        if gene_h.is_cuda:\n",
        "            DTYPE = torch.cuda.FloatTensor\n",
        "        else:\n",
        "            DTYPE = torch.FloatTensor\n",
        "\n",
        "        _gene_h = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), middle_output_gene), dim=1)\n",
        "        _graph_h = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), middle_output_graph), dim=1)\n",
        "\n",
        "        fusion_gene = torch.matmul(_gene_h, self.gene_factor)\n",
        "        fusion_graph = torch.matmul(_graph_h, self.graph_factor)\n",
        "        fusion_zy = fusion_gene * fusion_graph\n",
        "\n",
        "        output = torch.matmul(self.fusion_weights, fusion_zy.permute(1, 0, 2)).squeeze() + self.fusion_bias\n",
        "        output = output.view(-1, self.output_dim)\n",
        "\n",
        "        concatenated_h = torch.cat((gene_h,graph_h,output), dim=1)\n",
        "        output = self.final_linear(concatenated_h)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output, [decoded_gene,decoded_graph,encoded_graph], [middle_output_gene, middle_output_graph, gene_h, graph_h]"
      ],
      "metadata": {
        "id": "2foarwbbzIWj"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "t_cRxCyzTjmS"
      },
      "outputs": [],
      "source": [
        "class NetWrapper:\n",
        "    def __init__(self, model, device='cuda:0',features='BRCA-CC',model_indicator = 'graph', encoder = 'True', m = 0) -> None:\n",
        "        self.model = model\n",
        "        self.device = torch.device(device)\n",
        "        self.features = features\n",
        "        self.model_indicator = model_indicator\n",
        "        self.encoder = encoder\n",
        "        self.m = m\n",
        "\n",
        "    def loss_fn(self,batch,gene_tensors,optimizer,time,censor) -> float:\n",
        "        z = toTensorGPU(0)\n",
        "        censor = torch.tensor(censor, dtype=torch.float32).to(device)\n",
        "        loss = []\n",
        "        l2_loss = 0.0\n",
        "        # This can be changed when using a system with large RAM\n",
        "        if self.features == 'BRCA-SHUFFLE':\n",
        "            graph_set = list(set(batch))\n",
        "            graphs = disk_graph_load(graph_set)\n",
        "        batch_load = DataLoader(graphs, batch_size = len(graphs))\n",
        "        for d in batch_load:\n",
        "            d = d.to(self.device)\n",
        "        if self.model_indicator == 'combine':\n",
        "            gene_tensors = DataLoader(gene_tensors, batch_size = len(gene_tensors))\n",
        "            for e in gene_tensors:\n",
        "                e = e.to(self.device)\n",
        "\n",
        "        self.model.train()\n",
        "        optimizer.zero_grad()\n",
        "        if self.model_indicator == 'combine':\n",
        "            output,decoded,fusion_parameter = self.model(e, d)\n",
        "            #output,_ = self.model(e)\n",
        "        else:\n",
        "            output,_,_ = self.model(d)\n",
        "\n",
        "        current_batch_len = len(batch)\n",
        "        R_mat = np.zeros([current_batch_len, current_batch_len], dtype=int)\n",
        "        for i in range(current_batch_len):\n",
        "            for j in range(current_batch_len):\n",
        "                R_mat[i,j] = time[j] >= time[i]\n",
        "        R_mat = torch.FloatTensor(R_mat).to(device)\n",
        "        theta = output.reshape(-1)\n",
        "        exp_theta = torch.exp(theta)\n",
        "        survival_loss = -torch.mean((theta - torch.log(torch.sum(exp_theta*R_mat, dim=1))) * censor)\n",
        "        survival_loss = survival_loss / current_batch_len\n",
        "\n",
        "        if self.encoder == 'True':\n",
        "            if self.model_indicator == 'combine' and self.m == 0:\n",
        "                # Reconstruction losses\n",
        "                recon_loss_gene = F.mse_loss(decoded[0], e)\n",
        "                # Combine everything\n",
        "                loss = survival_loss + recon_loss_gene\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1)\n",
        "                optimizer.step()\n",
        "                return [loss.item(),survival_loss.item(),recon_loss_gene.item(),0,0]\n",
        "\n",
        "            else:\n",
        "                # Reconstruction losses\n",
        "                recon_loss_gene = F.mse_loss(decoded[0], e)\n",
        "                recon_loss_graph = F.mse_loss(decoded[1],decoded[2])\n",
        "                #Similarity loss\n",
        "                similarity_loss = F.mse_loss(fusion_parameter[0], fusion_parameter[1])\n",
        "                # Combine everything\n",
        "                loss = survival_loss + 0.5*(recon_loss_gene + recon_loss_graph) + similarity_loss\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1)\n",
        "                optimizer.step()\n",
        "                return [loss.item(),survival_loss.item(),recon_loss_gene.item(),recon_loss_graph.item(),similarity_loss.item()]\n",
        "        else:\n",
        "            loss = survival_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            return loss.item()\n",
        "\n",
        "    def censor_data(self,graphs, censor_time): # The censor time measured in years\n",
        "        cen_time = 365 * censor_time\n",
        "        for graph in graphs:\n",
        "            if self.features == 'BRCA-SHUFFLE':\n",
        "                time = graph[1][1]\n",
        "            else:\n",
        "                time = graph.e_time\n",
        "            if time > cen_time:\n",
        "                if self.features == 'BRCA-SHUFFLE':\n",
        "                    graph[1] = (0,cen_time,graph[1][2])\n",
        "                else:\n",
        "                    graph.event = toTensor(0)\n",
        "                    graph.e_time = toTensor(cen_time)\n",
        "            else:\n",
        "                continue\n",
        "        return graphs\n",
        "\n",
        "    def train(self,training_data,validation_data,max_batches=200,num_logs=50,optimizer=torch.optim.Adam,\n",
        "              early_stopping = 0, return_best = False, batch_size = 10,num_epochs=10) -> float:\n",
        "            return_best = return_best and validation_data is not None\n",
        "            log_interval = max_batches // num_logs\n",
        "            loss_vals = {}\n",
        "            loss_vals['train'] = []\n",
        "            loss_vals['validation'] = []\n",
        "\n",
        "            concords = []\n",
        "            c_best = 0.5\n",
        "            best_model = deepcopy(self.model)\n",
        "            for epoch in tqdm(range(num_epochs)):\n",
        "                if self.model_indicator == 'combine':\n",
        "                    losses = [0,0,0,0,0]\n",
        "                else:\n",
        "                    losses = 0\n",
        "                for i in range(0, len(training_data), batch_size):\n",
        "                    batch_pairs = []\n",
        "                    gene_tensors = []\n",
        "                    time = []\n",
        "                    censor = []\n",
        "                    if i + batch_size < len(training_data):\n",
        "                        for j in range(i, i + batch_size):\n",
        "                            graph_i = training_data[j][0]\n",
        "                            gene_i = training_data[j][1][2]\n",
        "                            time_i = training_data[j][1][1]\n",
        "                            censor_i = training_data[j][1][0]\n",
        "                            batch_pairs.append(graph_i)\n",
        "                            gene_tensors.append(gene_i)\n",
        "                            time.append(time_i)\n",
        "                            censor.append(censor_i)\n",
        "                        loss = self.loss_fn(batch_pairs,gene_tensors,optimizer,time,censor)\n",
        "                        if self.model_indicator == 'combine':\n",
        "                            losses = list(map(operator.add, losses, loss))\n",
        "                        else:\n",
        "                            losses += loss\n",
        "\n",
        "                loss_vals['train'].append(losses)\n",
        "\n",
        "                eval = Evaluator(self.model,model_indicator=self.model_indicator,device='cuda:0',features='BRCA-SHUFFLE')\n",
        "                concord = eval.test_evaluation(validation_data)\n",
        "                concords.append(concord)\n",
        "\n",
        "            return loss_vals, concords, self.model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "x3GyQZdoTjmT"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Evaluator:\n",
        "    def __init__(self, model, model_indicator, device='cuda:0',features = 'BRCA-SHUFFLE') -> None:\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.features = features\n",
        "        self.model_indicator = model_indicator\n",
        "\n",
        "    def get_predictions(self,model,graphs,device=torch.device('cuda:0')) -> list:\n",
        "        outputs = []\n",
        "        e_and_t = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i in range(len(graphs)):\n",
        "                graph = graphs[i]\n",
        "                if self.features == 'BRCA-SHUFFLE':\n",
        "                    tag = [graph[0]]\n",
        "                    temp = [graph[1], graph[1]]\n",
        "                    graph = disk_graph_load(tag)\n",
        "                else:\n",
        "                    temp = [graph.event.item(),graph.e_time.item()]\n",
        "                    graph = [graph]\n",
        "                size = 1\n",
        "                loader = DataLoader(graph, batch_size=size)\n",
        "                for d in loader:\n",
        "                    d = d.to(device)\n",
        "                z = model(d)\n",
        "                z = toNumpy(z)\n",
        "                outputs.append(z[0])\n",
        "                e_and_t.append(temp)\n",
        "        return outputs, e_and_t\n",
        "\n",
        "    def test_evaluation(self,testDataset):\n",
        "        predictions, e_and_t = get_predictions(self.model,testDataset,self.model_indicator,self.features)\n",
        "        T = [x[1] for x in e_and_t]\n",
        "        E = [x[0] for x in e_and_t]\n",
        "        concord = 1 - cindex(T,predictions,E)\n",
        "        return concord\n",
        "\n",
        "    def K_M_Curves(self, graphs, split_val, mode = 'Train') -> None:\n",
        "        outputs, e_and_t = get_predictions(self.model,graphs,self.features)\n",
        "        T = [x[1] for x in e_and_t]\n",
        "        E = [x[0] for x in e_and_t]\n",
        "        mid = np.median(outputs)\n",
        "        if mode != 'Train':\n",
        "            if split_val > 0:\n",
        "                mid = split_val\n",
        "        else:\n",
        "            print(mid)\n",
        "        T_high = []\n",
        "        T_low = []\n",
        "        E_high = []\n",
        "        E_low = []\n",
        "        for i in range(len(outputs)):\n",
        "          if outputs[i] <= mid:\n",
        "            T_high.append(T[i])\n",
        "            E_high.append(E[i])\n",
        "          else:\n",
        "            T_low.append(T[i])\n",
        "            E_low.append(E[i])\n",
        "        km_high = KaplanMeierFitter()\n",
        "        km_low = KaplanMeierFitter()\n",
        "        ax = plt.subplot(111)\n",
        "        ax = km_high.fit(T_high, event_observed=E_high, label = 'High').plot_survival_function(ax=ax)\n",
        "        ax = km_low.fit(T_low, event_observed=E_low, label = 'Low').plot_survival_function(ax=ax)\n",
        "        from lifelines.plotting import add_at_risk_counts\n",
        "        add_at_risk_counts(km_high, km_low, ax=ax)\n",
        "        plt.title('Kaplan-Meier estimate')\n",
        "        plt.ylabel('Survival probability')\n",
        "        plt.show()\n",
        "        plt.tight_layout()\n",
        "        from lifelines.statistics import logrank_test\n",
        "        results = logrank_test(T_low, T_high, E_low, E_high)\n",
        "        print(\"p-value %s; log-rank %s\" % (results.p_value, np.round(results.test_statistic, 6)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZBN6My4WTjmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63bd0ec6-ee89-4f19-e036-694a0802e16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 652/652 [10:00<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    device = {True:'cuda:0',False:'cpu'}[USE_CUDA]\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    from natsort import natsorted\n",
        "    # This is set up to run on colab vvv\n",
        "    survival_file = r'drive/MyDrive/SlideGraph/NIHMS978596-supplement-1.xlsx'\n",
        "    #gene_file = pd.read_csv('drive/MyDrive/SlideGraph/topics_brca_dawood.csv')\n",
        "    gene_file = pd.read_excel('drive/MyDrive/SlideGraph/656Genes_data.xlsx')\n",
        "    gene_file.set_index(gene_file.columns[0], inplace=True)\n",
        "    columns_to_drop = ['ER', 'PR', 'HER2', 'OS', 'OSTime', 'PFI', 'PFITime', 'DSS', 'DSSTime']\n",
        "    gene_file = gene_file.drop(columns=columns_to_drop)\n",
        "    # Log-transform the whole dataset\n",
        "    gene_file = gene_file.applymap(lambda x: np.log(1 + x))\n",
        "    # Z-score normalization for each column (each gene across all patients)\n",
        "    gene_file = (gene_file - gene_file.mean()) / gene_file.std()\n",
        "    # Define a function to categorize each column\n",
        "    def categorize_column(col):\n",
        "        upper_threshold = col.mean() + 1 * col.std()\n",
        "        lower_threshold = col.mean() - 1 * col.std()\n",
        "        return col.apply(lambda x: 1 if x > upper_threshold else (-1 if x < lower_threshold else 0))\n",
        "    # Apply the function to each column in gene_file\n",
        "    gene_file = gene_file.apply(categorize_column)\n",
        "    cols2read = [VARIABLES,TIME_VAR]\n",
        "    TS = pd.read_excel(survival_file).rename(columns= {'bcr_patient_barcode':'ID'}).set_index('ID')  # path to clinical file\n",
        "    TS = TS[cols2read][TS.type == 'BRCA']\n",
        "    # Conditionally set TIME_VAR\n",
        "    TS.loc[TS[TIME_VAR] >= 3650, TIME_VAR] = 3650\n",
        "    if SHUFFLE_NET:\n",
        "        bdir = r'drive/MyDrive/SlideGraph/ShuffleNet_0.8_dth_4K/'\n",
        "        # Set up directory for on disk dataset\n",
        "        directory = r'drive/MyDrive/SlideGraph/Graphs'\n",
        "        try:\n",
        "            os.mkdir(directory)\n",
        "        except FileExistsError:\n",
        "            pass\n",
        "    Exid = 'Slide_Graph CC_feats'\n",
        "    graphlist = glob(os.path.join(bdir, \"*.pkl\"))#[0:100]\n",
        "    device = 'cuda:0'\n",
        "    cpu = torch.device('cpu')\n",
        "\n",
        "    if FILTER_TRIPLE:\n",
        "        filter_file = 'drive/MyDrive/SlideGraph/TCGA-BRCA-DX_CLINI (8).xlsx'\n",
        "        cols = ['ERStatus','PRStatus','HER2FinalStatus']\n",
        "        db = pd.read_excel(filter_file).rename(columns= {'CompleteTCGAID':'ID'}).set_index('ID')\n",
        "        db = db[cols]\n",
        "\n",
        "    try:\n",
        "        os.mkdir(MODEL_PATH)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "    graphlist = natsorted(graphlist)\n",
        "    dataset = []\n",
        "    from tqdm import tqdm\n",
        "    for graph in tqdm(graphlist):\n",
        "        TAG = os.path.split(graph)[-1].split('_')[0][:12]\n",
        "        status = TS.loc[TAG,:][1]\n",
        "        event, event_time = TS.loc[TAG,:][0], TS.loc[TAG,:][1]\n",
        "\n",
        "        gene = gene_file.loc[TAG]\n",
        "        gene = torch.tensor(gene.to_numpy(), dtype=torch.float)\n",
        "\n",
        "        if np.isnan(event):\n",
        "            continue\n",
        "        if SHUFFLE_NET:\n",
        "            G = pickleLoad(graph)\n",
        "            # Google Colab may sometimes produce \"Transport endpoint is not connected\" error here\n",
        "            # This is not a bug in the code. Rerunning the cell will fix this.\n",
        "            G.to('cpu')\n",
        "            gene.to('cpu')\n",
        "        else:\n",
        "            if USE_CUDA:\n",
        "                G = pickleLoad(graph)\n",
        "                G.to('cpu')\n",
        "                gene.to('cpu')\n",
        "            else:\n",
        "                G = torch.load(graph, map_location=device)\n",
        "        try:\n",
        "            G.y = toTensorGPU([int(status)], dtype=torch.long, requires_grad = False)\n",
        "        except ValueError:\n",
        "            continue\n",
        "        W = radius_neighbors_graph(toNumpy(G.coords), 1500, mode=\"connectivity\",include_self=False).toarray()\n",
        "        g = toGeometricWW(toNumpy(G.x),W,toNumpy(G.y))\n",
        "        g.coords = G.coords\n",
        "        g.event = toTensor(event)\n",
        "        g.e_time = toTensor(event_time)\n",
        "        if SHUFFLE_NET:\n",
        "            dataset.append([TAG,(event,event_time,gene)])\n",
        "            torch.save(g,directory+'/'+TAG+'.g')\n",
        "        else:\n",
        "            dataset.append(g)\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "txry3EFjTjmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15cf88c-ff49-4649-bfa2-3ac7467accb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:22<00:00, 10.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6711915535444948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:25<00:00, 10.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7028231797919762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:25<00:00, 10.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7634271099744245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:24<00:00, 10.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6330845771144278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [04:21<00:00, 10.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7915360501567398\n",
            "Performance on test data over 5 folds:\n",
            "0.7124124941164126 +/- 0.06509045140865043\n",
            "perf on each split was: [0.6711915535444948, 0.7028231797919762, 0.7634271099744245, 0.6330845771144278, 0.7915360501567398]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "trainingDataset = dataset.copy()\n",
        "event_vector = np.array([int(g[1][0]) for g in trainingDataset])\n",
        "\n",
        "folds = 5\n",
        "models = []\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "if SHUFFLE_NET:\n",
        "    G = torch.load(directory + f'/{dataset[0][0]}.g')\n",
        "else:\n",
        "    G = dataset[0]\n",
        "\n",
        "converg_vals = []\n",
        "fold_concord = []\n",
        "eval_metrics = []\n",
        "LEARNING_RATE = 0.0001\n",
        "WEIGHT_DECAY = 0.1\n",
        "\n",
        "'''Change to either graph or combine for different network'''\n",
        "indicator = 'combine'\n",
        "\n",
        "for train_index, vali_index in SplitBrcaData(trainingDataset,folds,SHUFFLE_NET,0.2):\n",
        "    # get indices for training and testing\n",
        "        trainingDataset = dataset.copy()\n",
        "    # Set up model and optimizer\n",
        "\n",
        "        '''Remove the # in the model, net for testing LMF network'''\n",
        "        model = LMF(gene_in = len(dataset[0][1][2]), graph_in = G.x.shape[1],\n",
        "                    hidden_dims = [[24,24,16,16,4], [24,24,16,16,4]], dropouts = [0.5,0.5,0.5],\n",
        "                    output_dim = 1, rank = 2)\n",
        "        net = NetWrapper(model,device = device,features = 'BRCA-SHUFFLE', model_indicator=indicator, encoder='True',m=0)\n",
        "\n",
        "        '''Remove the # in the model, net for testing second fusion network'''\n",
        "        #model = second_fusion(gene_in = len(dataset[0][1][2]), graph_in = G.x.shape[1],\n",
        "        #            hidden_dims = [[24,24,16,16,1], [24,24,16,16,1]], dropouts = [0.5,0.5,0.5],\n",
        "        #            LMF_output_dim = 1, rank = 2, middle_layers=[2,2], share_hidden_dim=[16,16,4])\n",
        "        #net = NetWrapper(model,device = device,features = 'BRCA-SHUFFLE', model_indicator=indicator, encoder='True',m=1)\n",
        "        '''Remove the # in the model, net for testing GNN network'''\n",
        "        #model = GNN(dim_features=G.x.shape[1],\n",
        "        #            dim_target = 1, layers = [64,32,16,16],\n",
        "        #            dropout = 0.0, pooling = 'mean', conv='EdgeConv', aggr = 'max')\n",
        "        #net = NetWrapper(model,device = device,features = 'BRCA-SHUFFLE', model_indicator=indicator, encoder='False')\n",
        "\n",
        "        model = model.to(device)\n",
        "        optimizer = optim.Adam(model.parameters(),\n",
        "                        lr=LEARNING_RATE,\n",
        "                        weight_decay=WEIGHT_DECAY,\n",
        "                        betas=(0.9, 0.999))\n",
        "        x_train = [trainingDataset[i] for i in train_index]\n",
        "        testDataset = [trainingDataset[i] for i in vali_index]\n",
        "        # Only censoring the test data\n",
        "        # x_val = net.censor_data(x_val,10)\n",
        "        losses, concords, BestModel, = net.train(x_train,testDataset,optimizer = optimizer,return_best = True,max_batches = NUM_BATCHES,num_epochs=50)\n",
        "        models.append(BestModel)\n",
        "        converg_vals.append(losses)\n",
        "        fold_concord.append(concords)\n",
        "        #m = max(concords)\n",
        "        eval_metrics.append(concords[-1])\n",
        "        print(concords[-1])\n",
        "\n",
        "avg_c = mean(eval_metrics)\n",
        "stdev_c = stdev(eval_metrics)\n",
        "\n",
        "print(f\"Performance on test data over {folds} folds:\")\n",
        "print(f\"{avg_c} +/- {stdev_c}\")\n",
        "print(f\"perf on each split was: {eval_metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fold_concord[0], label='Testing set C-index')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('C-index')\n",
        "plt.title('C-index Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ardcmlHUQah2",
        "outputId": "9082e10d-92dd-43cf-a864-c01cace5a2a3"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAIjCAYAAADxz9EgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACag0lEQVR4nOzdd3iUZdYG8Pudnt47qUAIPTFAQKoSCCIK2MDVRVhARVgLa2NVsLN2ZNcVZUFQPwW7qAhIFFRaMBB6TSEJ6QnpZZKZ9/tjMgMxhZSZvJOZ+3ddc0lm3nImBpKT5zznCKIoiiAiIiIiIiKzkEkdABERERERkS1hkkVERERERGRGTLKIiIiIiIjMiEkWERERERGRGTHJIiIiIiIiMiMmWURERERERGbEJIuIiIiIiMiMmGQRERERERGZEZMsIiIiIiIiM2KSRUREkhIEAc8++6zVX5OIiKi9mGQREVGXpKam4r777kNERAQ0Gg1cXV0xevRovP3226ipqZE6vG6Xn5+PRx99FFFRUXB0dISTkxNiY2Px4osvorS0VOrwiIioGyikDoCIiHquH374AbfffjvUajXmzJmDQYMGQavV4vfff8djjz2GEydO4P3332/zGjU1NVAobOPb0cGDBzF16lRUVlbi7rvvRmxsLADgjz/+wL/+9S/8+uuv2LFjh8RREhGRpdnGdzUiIup26enpmD17NkJDQ/Hzzz8jICDA9NrixYtx/vx5/PDDD1e9jkajsWSY3aa0tBQzZ86EXC7H4cOHERUV1eT1l156CWvXrjXLvaqqquDk5GSWaxERkfmxXJCIiDrl1VdfRWVlJdatW9ckwTLq06cPHnrooate58/7p5599lkIgoDz589j7ty5cHd3h5ubG+bNm4fq6uom59bV1eGRRx6Bj48PXFxccPPNNyM7O7vF+1y8eBF/+9vf4OfnB7VajYEDB2L9+vWm12tqahAVFYWoqKgmZY4lJSUICAjAtddeC51O1+r7eO+993Dx4kW8+eabzRIsAPDz88PTTz/d6vs2CgsLw9y5c00fb9iwAYIgYPfu3XjggQfg6+uLXr164YsvvjA931IsgiDg+PHjpudOnz6N2267DZ6entBoNBg2bBi2bNnS6vshIqLOY5JFRESd8t133yEiIgLXXnutRa5/xx13oKKiAitXrsQdd9yBDRs24LnnnmtyzIIFC7Bq1SpMnjwZ//rXv6BUKnHjjTc2u1Z+fj5GjhyJnTt3YsmSJXj77bfRp08fzJ8/H6tWrQIAODg4YOPGjTh//jyeeuop07mLFy9GWVkZNmzYALlc3mq8W7ZsgYODA2677TbzfAL+5IEHHsDJkyexfPlyPPnkk7jxxhvh7OyMzz77rNmxmzdvxsCBAzFo0CAAwIkTJzBy5EicOnUKTz75JN544w04OTlhxowZ+Prrry0SLxGRPWO5IBERdVh5eTkuXryI6dOnW+weMTExWLdunenj4uJirFu3Dq+88goA4MiRI/j444/xwAMP4J133gFgSIjuuusuHD16tMm1nnrqKeh0Ohw7dgxeXl4AgPvvvx933nknnn32Wdx3331wcHBAXFwcHn/8cbzyyiuYOXMm8vPzsWnTJqxatQqRkZFtxnvq1ClERkZCpVKZ89Ng4unpicTExCaJ3k033YQvvvgCq1evNj2fl5eH3bt3N1kle+ihhxASEoKDBw9CrVYDMCRtY8aMwRNPPIGZM2daJGYiInvFlSwiIuqw8vJyAICLi4vF7nH//fc3+Xjs2LEoLi423Xvr1q0AgAcffLDJcQ8//HCTj0VRxJdffombbroJoiiiqKjI9EhISEBZWRkOHTpkOv7ZZ5/FwIEDcc899+CBBx7A+PHjm92jJeXl5Rb9fCxcuLDZStqsWbNQUFCAXbt2mZ774osvoNfrMWvWLACGcseff/7ZtDJofO/FxcVISEjAuXPncPHiRYvFTURkj7iSRUREHebq6goAqKioaNfxJSUl0Gq1po8dHBzg5ubW5jkhISFNPvbw8AAAXLp0Ca6urrhw4QJkMhl69+7d5Lh+/fo1+biwsBClpaV4//33W+10WFBQYPqzSqXC+vXrMXz4cGg0GnzwwQcQBOGq79HV1bXdn4/OCA8Pb/bclClT4Obmhs2bN2PixIkADKWC0dHRppW38+fPQxRFPPPMM3jmmWdavHZBQQGCgoIsFjsRkb1hkkVERB3m6uqKwMDAJo0V2nLLLbc0adBwzz33YMOGDW2e09r+J1EU2x0nAOj1egDA3XffjXvuuafFY4YMGdLk4+3btwMAamtrce7cuRYTnD+LiopCSkoKtFptl0oGW2uu4eDg0Ow5tVpt2lf13//+F/n5+dizZw9efvll0zHG9//oo48iISGhxWv36dOn0/ESEVFzTLKIiKhTpk2bhvfffx/79u3DqFGj2jz2jTfewKVLl0wfBwYGdvn+oaGh0Ov1SE1NbbJ6debMmSbHGTsP6nQ6xMfHX/W6R48exfPPP4958+YhJSUFCxYswLFjx6668nbTTTdh3759+PLLL3HnnXde9T4eHh7NhhNrtVrk5uZe9dwrzZo1Cxs3bkRiYiJOnToFURRNpYIAEBERAQBQKpXtev9ERNR13JNFRESd8vjjj8PJyQkLFixAfn5+s9dTU1Px9ttvAwBiY2MRHx9vegwYMKDL97/hhhsAAKtXr27yvLFboJFcLsett96KL7/8ssWVt8LCQtOf6+vrMXfuXAQGBuLtt9/Ghg0bkJ+fj0ceeeSq8dx///0ICAjAP/7xD5w9e7bZ6wUFBXjxxRdNH/fu3Ru//vprk2Pef//9NtvEtyQ+Ph6enp7YvHkzNm/ejBEjRjRZefP19cWECRPw3nvvtZjAXfn+iYjIPLiSRUREndK7d2988sknmDVrFvr37485c+Zg0KBB0Gq12Lt3Lz7//PMm857MLTo6GnfeeSf++9//oqysDNdeey0SExNx/vz5Zsf+61//wi+//IK4uDgsXLgQAwYMQElJCQ4dOoSdO3eipKQEAPDiiy8iJSUFiYmJcHFxwZAhQ7B8+XI8/fTTuO222zB16tRW4/Hw8MDXX3+NqVOnIjo6GnfffTdiY2MBAIcOHcKnn37aZMVvwYIFuP/++3Hrrbdi0qRJOHLkCLZv3w5vb+8OfR6USiVuueUWbNq0CVVVVXj99debHfPOO+9gzJgxGDx4MBYuXIiIiAjk5+dj3759yM7OxpEjRzp0TyIiugqRiIioC86ePSsuXLhQDAsLE1Uqleji4iKOHj1a/Pe//y3W1tZe9XwA4ooVK0wfr1ixQgQgFhYWNjnugw8+EAGI6enppudqamrEBx98UPTy8hKdnJzEm266SczKymp2TVEUxfz8fHHx4sVicHCwqFQqRX9/f3HixIni+++/L4qiKCYnJ4sKhUL8+9//3uS8hoYGcfjw4WJgYKB46dKlq76fnJwc8ZFHHhEjIyNFjUYjOjo6irGxseJLL70klpWVmY7T6XTiE088IXp7e4uOjo5iQkKCeP78eTE0NFS85557mr3vgwcPtnrPn376SQQgCoIgZmVltXhMamqqOGfOHNHf319UKpViUFCQOG3aNPGLL7646nsiIqKOEUSxgzuIiYiIiIiIqFXck0VERERERGRGTLKIiIiIiIjMiEkWERERERGRGTHJIiIiIiIiMiMmWURERERERGbEJIuIiIiIiMiMOIy4BXq9Hjk5OXBxcYEgCFKHQ0REREREEhFFERUVFQgMDIRM1r41KiZZLcjJyUFwcLDUYRARERERkZXIyspCr1692nUsk6wWuLi4ADB8Il1dXSWOhoiIiIiIpFJeXo7g4GBTjtAeTLJaYCwRdHV1ZZJFREREREQd2kbExhdERERERERmxCSLiIiIiIjIjJhkERERERERmRH3ZHWSKIpoaGiATqeTOhSiTpPL5VAoFBxVQERERGRGTLI6QavVIjc3F9XV1VKHQtRljo6OCAgIgEqlkjoUIiIiIpvAJKuD9Ho90tPTIZfLERgYCJVKxVUA6pFEUYRWq0VhYSHS09PRt2/fdg/YIyIiIqLWMcnqIK1WC71ej+DgYDg6OkodDlGXODg4QKlU4sKFC9BqtdBoNFKHRERERNTj8dfWncTf+JOt4NcyERERkXnxpysiIiIiIiIzYpJFRERERERkRkyyyOyeffZZREdHSx2G5Mz1eQgLC8OqVau6fB0iIiIi6h5MsuyAIAhtPp599tkuXfubb75p8tyjjz6KxMTErgXdDVqKvTW//PILpk6dCi8vLzg6OmLAgAH4xz/+gYsXL7Z6Tk/5PBARERGReVlFkvXOO+8gLCwMGo0GcXFxSEpKavXYCRMmtJgo3HjjjaZj5s6d2+z1KVOmdMdbsUq5ubmmx6pVq+Dq6trkuUcffdSs93N2doaXl5dZryml9957D/Hx8fD398eXX36JkydPYs2aNSgrK8Mbb7zR6nm29nkgIiIiovaRPMnavHkzli5dihUrVuDQoUMYOnQoEhISUFBQ0OLxX331VZME4fjx45DL5bj99tubHDdlypQmx3366acWew+iKKJa29DtD1EU2xWfv7+/6eHm5gZBEJo8t2nTJvTv3x8ajQZRUVH473//azpXq9ViyZIlCAgIgEajQWhoKFauXAnAUMYGADNnzoQgCKaP/1wmN3fuXMyYMQOvv/46AgIC4OXlhcWLF6O+vt50TG5uLm688UY4ODggPDwcn3zyyVXL5Hbt2oURI0bAyckJ7u7uGD16NC5cuGB6/dtvv8U111wDjUaDiIgIPPfcc2hoaGgz9j/Lzs7Ggw8+iAcffBDr16/HhAkTEBYWhnHjxuF///sfli9f3mp8nfk8FBQU4KabbjJ9Hv7v//6v2XVLS0uxYMEC+Pj4wNXVFddffz2OHDkCACgsLIS/vz9efvll0/F79+6FSqXiqhoRERFRN5F8Ttabb76JhQsXYt68eQCANWvW4IcffsD69evx5JNPNjve09OzycebNm2Co6NjsyRLrVbD39/fcoFfoaZehwHLt3fLva508vkEOKq69r/w//7v/7B8+XL85z//QUxMDA4fPoyFCxfCyckJ99xzD1avXo0tW7bgs88+Q0hICLKyspCVlQUAOHjwIHx9ffHBBx9gypQpkMvlrd7nl19+QUBAAH755RecP38es2bNQnR0NBYuXAgAmDNnDoqKirBr1y4olUosXbq01UQbABoaGjBjxgwsXLgQn376KbRaLZKSkkyDoX/77TfMmTMHq1evxtixY5Gamop7770XALBixYp2x/75559Dq9Xi8ccfb/F1d3f3q36OO/J5mDt3LnJycvDLL79AqVTiwQcfbPZ5uP322+Hg4IAff/wRbm5ueO+99zBx4kScPXsWPj4+WL9+PWbMmIHJkyejX79++Otf/4olS5Zg4sSJHYqViIiIiDpH0iRLq9UiOTkZy5YtMz0nk8kQHx+Pffv2tesa69atw+zZs+Hk5NTk+V27dsHX1xceHh64/vrr8eKLL7ZaulVXV4e6ujrTx+Xl5Z14Nz3TihUr8MYbb+CWW24BAISHh+PkyZN47733cM899yAzMxN9+/bFmDFjIAgCQkNDTef6+PgAMCQaV0toPTw88J///AdyuRxRUVG48cYbkZiYiIULF+L06dPYuXMnDh48iGHDhgEA/ve//6Fv376tXq+8vBxlZWWYNm0aevfuDQDo37+/6fXnnnsOTz75JO655x4AQEREBF544QU8/vjjWLFiRbtjP3fuHFxdXREQENDm+2uvtj4PZ8+exY8//oikpCQMHz4cgOHr+8r39fvvvyMpKQkFBQVQq9UAgNdffx3ffPMNvvjiC9x7772YOnUqFi5ciLvuugvDhg2Dk5OTafWRiIiIiCxP0iSrqKgIOp0Ofn5+TZ738/PD6dOnr3p+UlISjh8/jnXr1jV5fsqUKbjlllsQHh6O1NRU/POf/8QNN9yAffv2tbhisXLlSjz33HOdfh8OSjlOPp/Q6fO7ct+uqKqqQmpqKubPn29aSQEMq0Rubm4ADCsrkyZNQr9+/TBlyhRMmzYNkydP7vC9Bg4c2ORzHxAQgGPHjgEAzpw5A4VCgWuuucb0ep8+feDh4dHq9Tw9PTF37lwkJCRg0qRJiI+Pxx133GFKho4cOYI9e/bgpZdeMp2j0+lQW1uL6upqODo6tituURRNq2NtcXZ2Nv357rvvxpo1a1o8rq3Pw6lTp6BQKBAbG2t6PSoqqslq2ZEjR1BZWdnsFwY1NTVITU01ffz6669j0KBB+Pzzz5GcnGxKyIiIiMg8UrJKEe7tBDcHpdShkBWSvFywK9atW4fBgwdjxIgRTZ6fPXu26c+DBw/GkCFD0Lt3b+zatavFkqlly5Zh6dKlpo/Ly8sRHBzc7jgEQehy2Z4UKisrAQBr165FXFxck9eMicA111yD9PR0/Pjjj9i5cyfuuOMOxMfH44svvujQvZTKpv8ACYIAvV7fheiBDz74AA8++CC2bduGzZs34+mnn8ZPP/2EkSNHorKyEs8995xphe5KGo2m3feIjIxEWVkZcnNz21zNSklJMf3Z1dW11eO6+nmorKxEQEAAdu3a1ey1K5Ox1NRU5OTkQK/XIyMjA4MHD273PYiIiKht+9OKMfv9/Qhyd8DHC+IQ7u109ZPIrkja+MLb2xtyuRz5+flNns/Pz79q+VlVVRU2bdqE+fPnX/U+ERER8Pb2xvnz51t8Xa1Ww9XVtcnDHvj5+SEwMBBpaWno06dPk0d4eLjpOFdXV8yaNQtr167F5s2b8eWXX6KkpASAIWnQ6XRdiqNfv35oaGjA4cOHTc+dP38ely5duuq5MTExWLZsGfbu3YtBgwbhk08+AWBIDs+cOdPsffXp0wcymazdsd92221QqVR49dVXW3y9tLQUAJpc39fXtz1vu5moqCg0NDQgOTnZ9NyZM2dM9zC+r7y8PCgUimbvy9vbG4ChDPfuu+/GrFmz8MILL2DBggVt7m8jIiKijvn5tOH76sXSGty+Zh9O5drPVhNqH0mXX1QqFWJjY5GYmIgZM2YAAPR6PRITE7FkyZI2z/38889RV1eHu++++6r3yc7ORnFxsdn21diS5557Dg8++CDc3NwwZcoU1NXV4Y8//sClS5ewdOlSvPnmmwgICEBMTAxkMhk+//xz+Pv7m1ZNwsLCkJiYiNGjR0OtVrdZ4teaqKgoxMfH495778W7774LpVKJf/zjH3BwcGi1VC89PR3vv/8+br75ZgQGBuLMmTM4d+4c5syZAwBYvnw5pk2bhpCQENx2222QyWQ4cuQIjh8/jhdffLHdsQcHB+Ott97CkiVLUF5ejjlz5iAsLAzZ2dn48MMP4ezs3GYb944wlmTed999ePfdd6FQKPDwww/DwcHBdEx8fDxGjRqFGTNm4NVXX0VkZCRycnLwww8/YObMmRg2bBieeuoplJWVYfXq1XB2dsbWrVvxt7/9Dd9//71Z4iQiIrJ3e1OLAAAuGgWKKusw6719+GDeCMSGdvznILJNkrdwX7p0KdauXYuNGzfi1KlTWLRoEaqqqkzdBufMmdOkMYbRunXrMGPGjGZ7UyorK/HYY49h//79yMjIQGJiIqZPn44+ffogIaH7901ZuwULFuB///sfPvjgAwwePBjjx4/Hhg0bTCtZLi4uePXVVzFs2DAMHz4cGRkZ2Lp1q2k16I033sBPP/2E4OBgxMTEdDqODz/8EH5+fhg3bhxmzpyJhQsXwsXFpdXSPkdHR5w+fRq33norIiMjce+992Lx4sW47777AAAJCQn4/vvvsWPHDgwfPhwjR47EW2+91aRxR3tjf+CBB7Bjxw5cvHgRM2fORFRUFBYsWABXV1ezzxj74IMPEBgYiPHjx+OWW27Bvffe22RlTBAEbN26FePGjcO8efMQGRmJ2bNn48KFC/Dz88OuXbuwatUqfPTRR3B1dYVMJsNHH32E3377De+++65ZYyUiIrJHZdX1OJFjWLn6+oFrERvqgfLaBtz9vwP4/VyRxNGRtRDE9g5bsqD//Oc/eO2115CXl4fo6GisXr3atEfIOJdow4YNpuPPnDmDqKgo7NixA5MmTWpyrZqaGsyYMQOHDx9GaWkpAgMDMXnyZLzwwgvNGmy0pry8HG5ubigrK2tWOlhbW4v09HSEh4d3aG8PdUx2djaCg4Oxc+dOth63MH5NExERtd+OE3m496NkRPg44ed/TEC1tgH3fZSM384VQSWX4d9/iUHCwO4ZI0Tdo63coDVWkWRZGyZZ3e/nn39GZWUlBg8ejNzcXDz++OO4ePEizp4926xZBJkXv6aJiIja77nvTuCDPRm4Ky4EL800NJaqa9DhoU9TsO1EHuQyAa/dNgS3XNNL4kjJXDqTZEleLkgEAPX19fjnP/+JgQMHYubMmfDx8TENJiYiIiKyFvtSiwEAo3pf3rKiVsjxn7/E4LbYXtDpRSz97Ag27s2QKEKyBj2v7zjZpISEBO6ZIyIiIqtWUqXF6bwKAMDIiKZ9ARRyGV69dQic1Qps2JuBFVtOoKK2Houv69OumZtkW7iSRURERETUDgfSDKtY/fxc4O2sbva6TCZgxU0D8NDEvgCA13ecxcofT4O7c+wPk6xO4l8WshX8WiYiImqfvS2UCv6ZIAh4ZFIknr6xPwDg/V/TsOyrY9Dp+f3WnjDJ6iDjHqHq6mqJIyEyD+PXMve/ERERtW1f40rWn0sFW7JgbARevXUIZAKw6WAWHtp0GNoGvaVDJCvBPVkdJJfL4e7ujoICw6RvR0dH1tlSjySKIqqrq1FQUAB3d3fI5XKpQyIiIrJaBRW1OF9QCUEARkZ4tuucO4YHw1mjwEObDuP7o7moqmvAf++KhYOK33NtHZOsTvD3N8w+MCZaRD2Zu7u76WuaiIiIWrY/rQQA0N/fFe6OqnafN3VwAJzUCtz30R/45Uwh7vkgCevuGQYXDStIbBmTrE4QBAEBAQHw9fVFfX291OEQdZpSqeQKFhERUTsYW7df28Z+rNaMj/TBR/Pj8LcPDiIpvQR/WXsAG/82Ap5O7U/WqGdhktUFcrmcP6ASERER2YH9aVdvetGW4WGe+PTekZizPgnHLpbhjvf24eP5cfB305gzTLISbHxBRERERNSG3LIapBdVQSYAw8Pbtx+rJYOC3PDZfaMQ4KbB+YJK3LZmLzKKqswYKVkLJllERERERG0wlgoODnKDaxf3UvXxdcbn949CmJcjsi/V4Pb39uF0Xrk5wiQrwiSLiIiIiKgNxiRrZCdLBf+sl4cjPrt/FKL8XVBYUYdZ7+1HSlapWa5N1oFJFhERERFRG4zzsUa1Yz5We/m6aLD53lGICXFHWU097lq7H3tTi8x2fZIWkywiIiIiolZklVQj+1INFDIBw8M6vx+rJW6OSnw8Pw6j+3ihSqvD3A8O4qeT+Wa9B0mDSRYRERERUSuMq1hDg93hpDZ/Y24ntQLr7hmOyQP8oG3Q4/6Pk/HN4Ytmvw91LyZZREREREStMO7HMmep4J9plHL8965rcMs1QdDpRTzyWQo+2pdhsfuR5THJIiIiIiJqgSiKl5MsMzW9aI1CLsPrtw3FPaNCIYrAM9+ewDu/nLfoPclymGQREREREbUgo7gaeeW1UMlliA31sPj9ZDIBz948EH+/vg8A4LXtZ/CvH09DFEWL35vMi0kWEREREVELjKtY0SHu0Cjl3XJPQRDwj8n98M+pUQCANbtT8fQ3x6HXM9HqSZhkERERERG1wNj04loLlwq25N5xvbHylsEQBOD/DmTikc9SUK/Td3sc1DlMsoiIiIiI/qTJfiwLNr1oy50jQrB6dgwUMgHfpuTg/o+SUVuvkyQW6hgmWUREREREf3K+oBJFlXVQK2SIDnGXLI6bhgZi7ZxhUCtkSDxdgL9tOIgGrmhZPSZZRERERER/YiwVHBbmAbWie/Zjtea6KF98+LcRcFLJsTe1GL+cKZQ0Hro6JllERERERH8idangn8VFeOGukaEAgE1JmRJHQ1fDJIuIiIiI6Ap6vYj9ad0zH6sjZg0PBgD8cqYAuWU1EkdDbWGSRURERER0hTP5FbhUXQ9HlRxDerlLHY5Jbx9nxIV7Qi8Cnx3MljocagOTLCIiIiKiKxhLBYeHeUIpt64fl/8SFwIA2HwwEzrOzrJa1vVVQ0REREQksX1WWCpolDDQH+6OSuSU1eLXc2yAYa2YZBERERERNdJduR/LSppeXEmjlOOWmF4AgE8PsAGGtWKSRURERETU6GROOSpqG+CiVmBgoKvU4bTozhGGBhiJpwtQUF4rcTTUEiZZRERERESN9qUVAQBGhHtCYWX7sYz6+rlgWKgHdHoRnyezAYY1ss6vHCIiIiIiCZjmY1nhfqwrzR5haICx6WAm9GyAYXWYZBERERERAWjQ6XEw4xIA60+ybhwcABeNAlklNdiTWiR1OPQnTLKIiIiIiAAcu1iGyroGuDsq0d/fOvdjGTmo5JgZEwQA+DSJDTCsDZMsIiIiIiIAextLBePCPSGTCRJHc3WzhxtKBnecyEdhRZ3E0dCVmGQREREREQFW3bq9JQMCXTE02B0NehFfHmIDDGvCJIuIiIiI7J62QY8/TPuxvCWOpv3+0tjOfVNSJkSRDTCsBZMsIiIiIrJ7R7JLUVOvg5eTCpF+zlKH027ThgTCSSVHRnE19jWuxJH0mGQRERERkd0ztm4f2dsLgmD9+7GMnNQKTG9sgLEpKUviaMiISRYRERER2T3TfKwesh/rSnc2NsDYdjwPJVVaiaMhgEkWEREREdm52nodkjN7xnyslgzu5YZBQa7Q6vT4ig0wrAKTLCIiIiKya4cyL0HboIevixoR3k5Sh9Mpxnbun7IBhlVgkkVEREREdm2/sVSwh+3HutL06EA4KOVILazCHxcuSR2O3WOSRURERER2bV8Pm4/VEheNEjcPDQQAfHogU+JoiEkWEREREdmtGq0OKVmlAIBre9B8rJbMbpyZ9cOxXJRV10scjX1jkkVEREREduuPCyWo14kIcndAsKeD1OF0SXSwO6L8XVDXoMfXh9kAQ0pWkWS98847CAsLg0ajQVxcHJKSklo9dsKECRAEodnjxhtvNB0jiiKWL1+OgIAAODg4ID4+HufOneuOt0JEREREPche43ysiJ67H8tIEATcOcLQAGPTwSw2wJCQ5EnW5s2bsXTpUqxYsQKHDh3C0KFDkZCQgIKCghaP/+qrr5Cbm2t6HD9+HHK5HLfffrvpmFdffRWrV6/GmjVrcODAATg5OSEhIQG1tbXd9baIiIiIqAfYd0XTC1swIyYIaoUMp/MqcLixDJK6n+RJ1ptvvomFCxdi3rx5GDBgANasWQNHR0esX7++xeM9PT3h7+9vevz0009wdHQ0JVmiKGLVqlV4+umnMX36dAwZMgQffvghcnJy8M0333TjOyMiIiIia1ZZ14BjF8sA2E6S5eagxI1DAgAAm5LYAEMqkiZZWq0WycnJiI+PNz0nk8kQHx+Pffv2tesa69atw+zZs+HkZJhpkJ6ejry8vCbXdHNzQ1xcXKvXrKurQ3l5eZMHEREREdm2g+kl0OlFhHg6Isi9Z+/HutJfGksGvzuSi4paNsCQgqRJVlFREXQ6Hfz8/Jo87+fnh7y8vKuen5SUhOPHj2PBggWm54zndeSaK1euhJubm+kRHBzc0bdCRERERD2MLbRub0lsqAf6+Dqjpl6Hb1NypA7HLkleLtgV69atw+DBgzFixIguXWfZsmUoKyszPbKysswUIRERERFZK+N+rGv72FaSdWUDjE9ZMigJSZMsb29vyOVy5OfnN3k+Pz8f/v7+bZ5bVVWFTZs2Yf78+U2eN57XkWuq1Wq4uro2eRARERGR7SqrrseJnMb9WDa2kgUAt8QEQSWX4UROOY5ll0kdjt2RNMlSqVSIjY1FYmKi6Tm9Xo/ExESMGjWqzXM///xz1NXV4e67727yfHh4OPz9/Ztcs7y8HAcOHLjqNYmIiIjIPhxIL4ZeBCJ8nODrqpE6HLPzcFLhhsGGBYZPuJrV7SQvF1y6dCnWrl2LjRs34tSpU1i0aBGqqqowb948AMCcOXOwbNmyZuetW7cOM2bMgJdX0988CIKAhx9+GC+++CK2bNmCY8eOYc6cOQgMDMSMGTO64y0RERERkZWz1f1YV5o93FAyuCXlIqrqGiSOxr4opA5g1qxZKCwsxPLly5GXl4fo6Ghs27bN1LgiMzMTMlnTXPDMmTP4/fffsWPHjhav+fjjj6Oqqgr33nsvSktLMWbMGGzbtg0aje39loKIiIiIOs7W5mO1ZGSEJ8K9nZBeVIXvjuRgduM+LbI8QeQo6GbKy8vh5uaGsrIy7s8iIiIisjElVVpc88JPAIA/no6Ht7Na4ogs573dqVj542kM7eWGb5eMkTqcHqkzuYHk5YJERERERN3pQGOpYD8/F5tOsADg1theUMoFHMkuMzX6IMtjkkVEREREdsW0H8uGSwWNvJ3VmDzA0ABjUxLHFHUXJllEREREZFf2Nu7HGmnDTS+uZJyZ9c3hi6jR6iSOxj4wySIiIiIiu1FQUYvzBZUQBENjCHtwbW8vhHg6oqKuAd8fzZE6HLvAJIuIiIiI7Mb+tBIAQH9/V7g7qiSOpnvIZAJmDQ8GAGw6yJLB7sAki4iIiIjshj20bm/J7cN6QSETkHzhEs7mV0gdjs1jkkVEREREdmN/Y9OLa+0syfJ10WBif18AwKdJmRJHY/uYZBERERGRXcgtq0F6URVkAjA83D72Y13J2ADjq0MXUVvPBhiWxCSLiIiIiOyCsVRwcJAbXDVKiaPpfmP7+iDI3QFlNfXYdjxP6nBsGpMsIiIiIrILxiRrpJ2VChrJr2iA8QlLBi2KSRYRERER2QXTEGI7mY/VktuH9YJMAJLSS5BaWCl1ODaLSRYRERER2byskmpkX6qBQiZgeJj97ccyCnBzwPVRhgYYm7iaZTFMsoiIiIjI5hlXsYb0coOTWiFxNNKaPdzQAOPLQxdR18AGGJbAJIuIiIiIbN7+VGPrdm+JI5HehH4+8HfVoKRKix0n8qUOxyYxySIiIiIimyaKIvba6RDilijkMtwxrBcAYNNBlgxaApMsIiIiIrJpGcXVyCuvhUouQ2yoh9ThWIU7hgdDEIA954txobhK6nBsDpMsIiIiIrJpxtbt0SHu0CjlEkdjHXp5OGJcXx8AwKaDWRJHY3uYZBERERGRTWPr9pbdOcLQAOPzP7KgbdBLHI1tYZJFRERERDZLFEXTShb3YzU1sb8vvJ3VKKrUIvEUG2CYE5MsIiIiIrJZqYWVKKqsg1ohQ0yIu9ThWBXlFQ0wPmXJoFkxySIiIiIim2VcxRoW5gG1gvux/sw4M+u3c4XIKqmWOBrbwSSLiIiIiGyWqXU792O1KMTLEWP6eEMUgc/+4GqWuTDJIiIiIiKbpNeL2J/G/VhXY2yA8dkfWWjQsQGGOTDJIiIiIiKbdCa/Apeq6+GokmNIL3epw7Fakwb4wctJhfzyOvxyplDqcGwCkywiIiIiskmX92N5Qinnj72tUSlkuC22sQFGUqbE0QAlVVq89dNZbNybIXUonaaQOgAiIiIiIkswzse6lqWCVzVreDDe+zUNu84UIKe0BoHuDt0ew8XSGvzvtzRsSspCTb0OXk4qzBoe3CMHSDPJIiIiIiKbo9OLOMAhxO0W4eOMkRGe2J9Wgs/+yMLD8ZHddu9z+RVYszsN36ZcRINeBAAMCnLFovF9euwKJJMsIiIiIrI5J3PKUV7bABe1AgMDXaUOp0e4c0SIIck6mIW/X98Xcplg0fsdyryEd3el4qeTlwchX9vbC4sm9MaYPt4QBMve35KYZBERERGRzdmXVgQAGBHuCUUPXQ3pbgkD/eHuqEROWS1+PVuI66J8zX4PURSx+2wh3t2VigPpJQAAQQASBvjj/gm9ER3sbvZ7SoFJFhERERHZHGPTC7Zubz+NUo5bYnph/Z50fJqUadYkq0Gnx9bjeXh3VypO5ZYDAJRyATNjgnDvuN7o4+tstntZAyZZRERERGRTGnR6HMy4BAAYyf1YHXLniGCs35OOxNMFKCivha+rpkvXq63X4YvkbLz/axoyS6oBAI4qOe4cEYL5Y8IlabDRHZhkEREREZFNOXaxDJV1DXBzUGJAAPdjdURfPxcMC/XAHxcu4fPkbCy+rk+nrlNeW4//25+Jdb+no6iyDgDg4ajE3GvDMWdUKDycVOYM2+owySIiIiIim2Js3T4ywhMyCzdvsEV3jgjBHxcuYdPBTCwa37tDn8OCilp8sCcDH++7gIq6BgBAoJsGC8dFYNbwYDiq7CP9sI93SURERER2w7Qfi6WCnTJ1cACe/e4EskpqsCe1CGP7+lz1nAvFVXj/1zR8npwNbYMeANDX1xn3j++Nm6MDe2wr9s5ikkVERERENkPboMcfjfuxRvX2ljianslBJcctMUHYuO8CPk3KbDPJOpFThjW70/DD0Rw0jrhCTIg7HpjQBxOjfO12JZFJFhERERHZjCPZpaip18HLSYVIP9vqWNedZo8IwcZ9F7DjRD4KK+rg46I2vSaKIg6kl+DdXanYfbbQ9PyEfj5YNL43RoR79ugZV+bAJIuIiIiIbIaxVHBkhJfd/6DfFf0DXBEd7I6UrFJ8eSgb94/vDb1eROLpAry76zwOZZYCAGQCMG1IIO4f3xsDOPTZhEkWEREREdkMU5LF+Vhd9pcRIUjJKsWmpEz4OKuxZncqzhVUAgBUChnuGNYLC8dGINTLSeJIrQ+TLCIiIiKyCbX1OiRnGvZjXcskq8umDQ3A89+fREZxNf7x+REAgItagbtHhWLe6DD4unRthpYtY5JFRERERDbhUOYlaBv08HVRI8Kbqytd5ahS4I5hhuHE3s5qzB8TjrtGhsBVo5Q6NKvHJIuIiIiIbMJ+Y+v23tyPZS7LpkZh6mB/DApyg0YplzqcHoNJFhERERHZBOMQYs7HMh+lXIZhYZ5Sh9Hj2NdUMCIiIiKySTVaHVKySgEYVrKIpMQki4iIiIh6vD8ulKBeJyLQTYMQT0epwyE7xySLiIiIiHq8fab9WN7cj0WSY5JFRERERD2eaT8WSwXJCkieZL3zzjsICwuDRqNBXFwckpKS2jy+tLQUixcvRkBAANRqNSIjI7F161bT688++ywEQWjyiIqKsvTbICIiIiKJVNY14Gh2GQAmWWQdJO0uuHnzZixduhRr1qxBXFwcVq1ahYSEBJw5cwa+vr7NjtdqtZg0aRJ8fX3xxRdfICgoCBcuXIC7u3uT4wYOHIidO3eaPlYo2ESRiIiIyFYdTC+BTi8ixNMRQe4OUodDJG2S9eabb2LhwoWYN28eAGDNmjX44YcfsH79ejz55JPNjl+/fj1KSkqwd+9eKJWGIWhhYWHNjlMoFPD397do7ERERERkHdi6nayNZOWCWq0WycnJiI+PvxyMTIb4+Hjs27evxXO2bNmCUaNGYfHixfDz88OgQYPw8ssvQ6fTNTnu3LlzCAwMREREBO666y5kZma2GUtdXR3Ky8ubPIiIiIioZ9iXyv1YZF0kS7KKioqg0+ng5+fX5Hk/Pz/k5eW1eE5aWhq++OIL6HQ6bN26Fc888wzeeOMNvPjii6Zj4uLisGHDBmzbtg3vvvsu0tPTMXbsWFRUVLQay8qVK+Hm5mZ6BAcHm+dNEhEREZFFldXU40QO92ORdelRm5X0ej18fX3x/vvvQy6XIzY2FhcvXsRrr72GFStWAABuuOEG0/FDhgxBXFwcQkND8dlnn2H+/PktXnfZsmVYunSp6ePy8nImWkREREQ9QFJ6CfQiEOHjBD9XjdThEAGQMMny9vaGXC5Hfn5+k+fz8/Nb3U8VEBAApVIJuVxueq5///7Iy8uDVquFSqVqdo67uzsiIyNx/vz5VmNRq9VQq9WdfCdEREREJJW9qUUAuB+LrItk5YIqlQqxsbFITEw0PafX65GYmIhRo0a1eM7o0aNx/vx56PV603Nnz55FQEBAiwkWAFRWViI1NRUBAQHmfQNEREREJClRFPHL6QIAwJg+3hJHQ3SZpHOyli5dirVr12Ljxo04deoUFi1ahKqqKlO3wTlz5mDZsmWm4xctWoSSkhI89NBDOHv2LH744Qe8/PLLWLx4semYRx99FLt370ZGRgb27t2LmTNnQi6X48477+z290dERERElnO+oBIZxdVQKWQYF+kjdThEJpLuyZo1axYKCwuxfPly5OXlITo6Gtu2bTM1w8jMzIRMdjkPDA4Oxvbt2/HII49gyJAhCAoKwkMPPYQnnnjCdEx2djbuvPNOFBcXw8fHB2PGjMH+/fvh48O/eERERES2ZMdJw7aT0b294KTuUa0GyMYJoiiKUgdhbcrLy+Hm5oaysjK4urpKHQ4RERERtWD6O3twJKsUK28ZjDtHhEgdDtmozuQGkpYLEhERERF1Rn55LY5klUIQgIn9faUOh6gJJllERERE1OP81FgqGB3sDl8Xtm4n68Iki4iIiIh6HGOSNXlAy6N/iKTEJIuIiIiIepSK2nrTfKxJA/wkjoaoOSZZRERERNSj7D5biHqdiAgfJ/TxdZY6HKJmmGQRERERUY+y44ShVJCrWGStmGQRERERUY9Rr9PjlzMFAIDJTLLISjHJIiIiIqIe40BaCSpqG+DtrEZ0sIfU4RC1iEkWEREREfUYO07mAQDi+/tCLhMkjoaoZUyyiIiIiKhHEEXR1Lqd+7HImjHJIiIiIqIe4fjFcuSW1cJRJcfoPt5Sh0PUKiZZRERERNQj/NRYKjiurw80SrnE0RC1jkkWEREREfUIOxpLBScPZKkgWTcmWURERERk9bJKqnE6rwJymYDro3ylDoeoTUyyiIiIiMjqGVexhod5wN1RJXE0RG1jkkVEREREVs+4H2vyAH+JIyG6OiZZRERERGTVLlVpkZReAoCt26lnYJJFRERERFbt59MF0ItAlL8Lgj0dpQ6H6KqYZBERERGRVdthLBUcyFJB6hmYZBERERGR1aqt1+HXs0UAgMksFaQegkkWEREREVmtPeeLUFOvQ6CbBgMDXaUOh6hdmGQRERERkdXaccLQun3SAD8IgiBxNETtwySLiIiIiKySTi8i8bQxyeJ+LOo5mGQRERERkVU6nHkJRZVauGgUiIvwlDoconZjkkVEREREVumnk4ZVrOujfKGU88dW6jn41UpEREREVkcURexoTLIms1SQehgmWURERERkdVILK5FeVAWVXIbx/XykDoeoQ5hkEREREZHVMa5ijertBWe1QuJoiDqGSRYRERERWR1j6/bJAzmAmHoeJllEREREZFUKymuRklUKAIjvzySLeh4mWURERERkVXaeKgAADA12h5+rRuJoiDqOSRYRERERWZUdJ/MAAJMHcBWLeiYmWURERERkNSrrGrD3fDEAJlnUczHJIiIiIiKr8evZQmh1eoR7O6GPr7PU4RB1CpMsIiIiIrIaO04YSgUnDfCDIAgSR0PUOUyyiIiIiMgq1Ov0+Pm0oenFJJYKUg/GJIuIiIiIrEJSegnKaxvg5aTCNSEeUodD1GlMsoiIiIjIKvx00jCAeGJ/X8hlLBWknotJFhERERFJThRFU5I1aYC/xNEQdQ2TLCIiIiKS3ImcclwsrYGDUo6xfb2lDoeoS5hkEREREZHkjKtYY/t6Q6OUSxwNUdcwySIiIiIiye1oTLImD2SpIPV8TLKIiIiISFJZJdU4lVsOmQBcH+UrdThEXcYki4iIiIgktfOUYRVrWJgnPJ1UEkdD1HVMsoiIiIhIUjtONJYKcgAx2QgmWUREREQkmdJqLZIySgAAk9m6nWyE5EnWO++8g7CwMGg0GsTFxSEpKanN40tLS7F48WIEBARArVYjMjISW7du7dI1iYiIiEgaP58ugE4vIsrfBSFejlKHQ2QWkiZZmzdvxtKlS7FixQocOnQIQ4cORUJCAgoKClo8XqvVYtKkScjIyMAXX3yBM2fOYO3atQgKCur0NYmIiIhIOpcHELNUkGyHIIqiKNXN4+LiMHz4cPznP/8BAOj1egQHB+Pvf/87nnzyyWbHr1mzBq+99hpOnz4NpVJplmu2pLy8HG5ubigrK4Orq2sn3x0RERERtaW2XodrXvgJ1VodtiwZjSG93KUOiaiZzuQGkq1kabVaJCcnIz4+/nIwMhni4+Oxb9++Fs/ZsmULRo0ahcWLF8PPzw+DBg3Cyy+/DJ1O1+lrAkBdXR3Ky8ubPIiIiIjIsvamFqFaq4O/qwaDg9ykDofIbCRLsoqKiqDT6eDn13Rp2M/PD3l5eS2ek5aWhi+++AI6nQ5bt27FM888gzfeeAMvvvhip68JACtXroSbm5vpERwc3MV3R0RERERXc2WpoCAIEkdDZD6SN77oCL1eD19fX7z//vuIjY3FrFmz8NRTT2HNmjVduu6yZctQVlZmemRlZZkpYiIiIiJqiV4v4qeThj3z3I9FtkYh1Y29vb0hl8uRn5/f5Pn8/Hz4+7fcvjMgIABKpRJyudz0XP/+/ZGXlwetVtupawKAWq2GWq3uwrshIiIioo44nFWKoso6uKgVGBnhJXU4RGYl2UqWSqVCbGwsEhMTTc/p9XokJiZi1KhRLZ4zevRonD9/Hnq93vTc2bNnERAQAJVK1alrEhEREVH3M5YKTojyhUrRo4qriK5K0q/opUuXYu3atdi4cSNOnTqFRYsWoaqqCvPmzQMAzJkzB8uWLTMdv2jRIpSUlOChhx7C2bNn8cMPP+Dll1/G4sWL231NIiIiIpLejpOG/fKTWSpINkiyckEAmDVrFgoLC7F8+XLk5eUhOjoa27ZtMzWuyMzMhEx2OQ8MDg7G9u3b8cgjj2DIkCEICgrCQw89hCeeeKLd1yQiIiIiaaUWViKtsApKuYAJ/XykDofI7CSdk2WtOCeLiIiIyHLW7E7Fv348jbF9vfHR/DipwyFqU4+ak0VERERE9mnHicZSwYGtNyYj6smYZBERERFRtymoqMXhrFIAwKT+3M5BtolJFhERERF1m8RTBRBFYEgvN/i7aaQOh8gimGQRERERUbcxtm5nV0GyZUyyiIiIiKhbVNU14PfzRQCASQO4H4tsF5MsIiIiIuoWv54thLZBj1AvR0T6OUsdDpHFMMkiIiIiom5hLBWc1N8PgiBIHA2R5TDJIiIiIiKLq9fpkXi6AAAwifuxyMYxySIiIiIiizuYUYKymnp4OqkQG+ohdThEFsUki4iIiIgszlgqeH2ULxRy/ghKts3sX+GiKJr7kkRERHZBFEW8+dNZfPZHltShEJmVKIrYcaJxPxZLBckOdCrJmjt3Lqqqqpo9n5GRgXHjxnU5KCIiInu0L60YqxPP4Ykvj+JIVqnU4RCZzancClwsrYFGKcO4vj5Sh0NkcZ1Kso4cOYIhQ4Zg3759puc2btyIoUOHwtvb22zBERER2ZOfTxmaAogi8PQ3x6HTszqEbIOxVHBMHx84qOQSR0NkeZ1KspKSknDLLbdgwoQJ+Oc//4k77rgDS5Ysweuvv46vv/7a3DESERHZBWPnNQA4drEMnxy4IGE0ROaz42QeAGDyQJYKkn1QdOYkpVKJ1157DY6OjnjhhRegUCiwe/dujBo1ytzxERER2YW0wkqkF1VBKRfwcHwkXtt+Bq9uP4MpgwLg46KWOjyiTrtYWoMTOeWQCcDEKF+pwyHqFp1ayaqvr8c//vEPvPLKK1i2bBlGjRqFW265BVu3bjV3fERERHYhsbFUcGSEF+4f3xuDglxRUduAlVtPSRwZUdf8dMKwihUb6gEvZ/7CgOxDp5KsYcOGYcuWLdi1axdeeukl7Nq1Cw8//DBuueUWPPDAA+aOkYiIyObtPHW5vbVcJuDFGYMhCMBXhy9if1qxxNERdd5PjV/bkwf4SxwJUffpdJKVkpKCkSNHAgAEQcATTzyBffv24ddffzVrgERERLaurLoef1y4BACI72/YsxId7I6/jAgBADzzzXHU6/SSxUfUWWXV9TiQVgKArdvJvnQqyVq3bh2cnJyaPR8TE4Pk5OQuB0VERGRPdp0tgE4vItLPGcGejqbnH0+IgpeTCucKKrH+93QJIyTqnF/OFKCh8Ws7zLv5z45EtqrTw4g/+ugjjB49GoGBgbhwwdD9aNWqVdi2bZvZgiMiIrIHPzd2Fbw+qulv+t0clVg2tT8AYNXOc8gpren22Ii6wti6natYZG86lWS9++67WLp0KaZOnYrS0lLodDoAgLu7O1atWmXO+IiIiGxag06PXWcKAQDx/Zt3Xrv1miCMCPNETb0Oz393srvDI+q0ugYddp0x/AJhEvdjkZ3pVJL173//G2vXrsVTTz0FufzyQLlhw4bh2LFjZguOiIjI1v1x4RLKaurh4ahETIhHs9cFQcALMwZBLhOw7UQefrlilhaRNdubWowqrQ5+rmoMCXKTOhyibtWpJCs9PR0xMTHNnler1aiqqupyUERERPbCWCp4XT9DV8GW9PN3wfwx4QCAFVtOoLZe123xEXWWsVQwvr8fZK18bRPZqk4lWeHh4UhJSWn2/LZt29C/f/+uxkRERGQ3jK3bJ/Zve8/KQxP7wt9Vg8ySavx3V2p3hEbUaXq9yP1YZNc6lWQtXboUixcvxubNmyGKIpKSkvDSSy9h2bJlePzxx80dIxERkU1KL6pCWmEVFDIBYyO92zzWSa3AipsGAADW7EpFehErR8h6HckuRWFFHZzVCozq7SV1OETdTtGZkxYsWAAHBwc8/fTTqK6uxl/+8hcEBgbi7bffxuzZs80dIxERkU1KbFzFiovwhKtGedXjpwzyx/hIH+w+W4jl3x7Hh38bAUFgGRZZnx2Nq1jj+/lArZBf5Wgi29PpFu533XUXzp07h8rKSuTl5SE7Oxvz5883Z2xEREQ2rbXW7a0RBAHP3TwQKoUMv50rwtZjeZYMj6jTjKWCk1kqSHaq00mWkaOjI3x9m7ecJSIiotaV19YjKb0EQMut21sT5u2EReN7AwCe//4EKusaLBKfrdpzvgjJFy5JHYZNSyusxPmCSihkAib048+IZJ/aXS4YExPT7pKEQ4cOdTogIiIie7D7TCEa9CJ6+zgh1MupQ+cumtAb36RcxIXiaqz66SyenjbAQlHaltN55bh73QE4KOVIfnoSHFQsY7ME4yrWyAgvuDlcvQyWyBa1eyVrxowZmD59OqZPn46EhASkpqZCrVZjwoQJmDBhAjQaDVJTU5GQkGDJeImIiGyCsVQw/ipdBVuiUcrx7M0DAQAf7M3Aqdxys8Zmq97/NQ2iCFRrdTicydUsSzGVCg5kqSDZr3avZK1YscL05wULFuDBBx/ECy+80OyYrKws80VHRERkgxp0evxyxpBkXa11e2uu6+eLGwb548fjeXjmm+P47L5RnEXUhpzSGmxJyTF9vD+tGNf2abujI3VcUWUdkhsT2M78AoHIVnRqT9bnn3+OOXPmNHv+7rvvxpdfftnloIiIiGzZ4axSlFbXw81BiWtC3Dt9nWemDYCjSo4/LlzCl4eyzRegDVr/ezoa9CJUCsOPPvsb98OReSWeyocoAoOCXBHo7iB1OESS6VSS5eDggD179jR7fs+ePdBoNF0OioiIyJYZBxBf188HCnnne1AFujvg4fi+AICVP55GabXWLPHZmrLqenyalAkAeHJKFAAgJasUtfU6KcOySZe7CvpLHAmRtDo1J+vhhx/GokWLcOjQIYwYMQIAcODAAaxfvx7PPPOMWQMkIiKyNYmnGlu3m6Gcat7ocHyRnI2z+ZV4dfsZvDxzcJevaWs+PnABVVodovxdMPfaMPx3VyqKKuuQklWKkREclGsu2gY9fjtXBACYxNbtZOc69euzJ598Ehs3bkRycjIefPBBPPjggzh06BA++OADPPnkk+aOkYiIyGZcKK4ytbceH+nT5esp5TK8OMOQWH2alMmGDn9SW6/DB3syAAD3jY+ATCZgZIQnAMO+LDKfrEvVqGvQw0EpR5S/i9ThEEmq0zUKd9xxB/bs2YOSkhKUlJRgz549uOOOO8wZGxERkc0xrmIND/M0W3vrEeGeuPWaXhBF4OlvjkOnF81yXVvw9eGLKKqsQ6CbBtOGBAIA4hpXrw6kcV+WOWUUVQEAwr2d2j32h8hWdWkYsVarRXZ2NjIzM5s8iIiIqGXG1u0TOzCAuD2WTY2Cq0aBEznl+Hj/BbNeu6fS6UWs/TUNADB/bASUjfvfRoYbVrIOZV5CXQP3ZZlL+hVJFpG961SSde7cOYwdOxYODg4IDQ1FeHg4wsPDERYWhvDwcHPHSEREZBMqautxIN1QotbZ1u2t8XZW4/HGpg6vbz+Dgopas16/J/rpZD7Siqrg5qDE7OHBpuf7+DrDy0mFugY9jmaXSRihbUljkkVk0qnGF3PnzoVCocD333+PgIAALgkTERG1w69ni1CvExHh7WSRH0TvHBGCz//IwpHsMrz8wymsmh1j9nv0FKIoYs3uVADAX0eGwkl9+UceQRAQF+GJrcfysD+1GMPDPKUK06YYywXDmGQRdS7JSklJQXJyMqKioswdDxERkc1KPG1ob23uUkEjuUzAizMG4+Z3fsc3KTm4Y3gwru1tnwN3D2ZcQkpWKVQKGe65NqzZ63HhXth6LA8H0kvw9+4PzyaxXJDosk6VCw4YMABFRUXmjoWIiMhm6fQidp0pBGD+UsErDe7lhr+ODAUAPPPNcWgb9Ba7lzV7r3EV67bYXvBxUTd7Pa6xw2DyhUt2+zkypxqtDrllhhLVCCZZRJ1Lsl555RU8/vjj2LVrF4qLi1FeXt7kQURERE2lZF1CSZUWrhoFYkM9LHqvf0zuB29nFVILq/C/39Msei9rdDa/AomnCyAIwMKxES0eE+nrAg9HJWrqdTh2sbR7A7RBGcWGVSw3ByU8nFQSR0MkvU4lWfHx8di/fz8mTpwIX19feHh4wMPDA+7u7vDwsOw3DiIiop5oZ2Pr9gn9fE1d7izFzUGJp27sDwBYnXgO2ZeqLXo/a/N+Y0fBKQP9Wy1dk8kEjAg3zstiK/euYqkgUVOd2pP1yy+/mDsOIiIim5Z4yrL7sf5sRnQQNiVl4UB6CZ777iTWzhnWLfeVWm5ZDb5NuQgAuHdcy6tYRnHhXth+Ih8H0kuw+LruiM52GZMslgoSGXQqyRo/fry54yAiIrJZWSXVOJtfCblMwITI7kmyBEHAizMG4Ya3f8NPJ/OReCrfonvBrMUHezJQrxMRF+6JmJC2q2tM+7IySlCv01t8hdGWpbOzIFET7U6yjh49ikGDBkEmk+Ho0aNtHjtkyJAuB0ZERGQrjKtYw0I94Oao7Lb79vVzwfyx4XhvdxpWbDmBa3t7w0El77b7d7eymnp8ciATAHD/+N5XPb6/vyvcHJQoq6nH8YtlV03KqHUsFyRqqt2/somOjjZ1FIyOjkZMTAyio6ObPWJiOj6T45133kFYWBg0Gg3i4uKQlJTU6rEbNmyAIAhNHhqNpskxc+fObXbMlClTOhwXERGROSSeNuzH6q5SwSs9eH1fBLppkH2pBv/ddb7b79+dPjmQicq6BvTzc8GEfj5XPV4mE0wzsg6kc19WV2QwySJqot0rWenp6fDx8TH92Vw2b96MpUuXYs2aNYiLi8OqVauQkJCAM2fOwNe35W9Grq6uOHPmjOnjloYhT5kyBR988IHpY7W6eftWIiIiS6usa8CBxsYKUpTrOakVWH7TQNz/cTLe252GGTFB6O3j3O1xWFpdgw7r9xh+Prl3XESLPxu0ZGSEJ3aeyseBtOJ2rX5Rc2XV9Siu0gJguSCRUbuTrNDQ0Bb/3FVvvvkmFi5ciHnz5gEA1qxZgx9++AHr16/Hk08+2eI5giDA39+/zeuq1eqrHkNERGRpv50thFanR5iXo2RNARIG+uG6fj745UwhVnx7Ah/NH9HuJKSn+ObwRRRW1CHATYObhga2+7yREV4AgD8yLqFBp4eC+7I6LL2xfbuvixrO6k5t9yeyOV3+l8TV1RVpaZ2bwaHVapGcnIz4+PjLAclkiI+Px759+1o9r7KyEqGhoQgODsb06dNx4sSJZsfs2rULvr6+6NevHxYtWoTi4uJWr1dXV8dZX0REVkwURdTreubA2Mulgn6SJTaCIOC5mwdBrZDh9/NF+P5oriRxWIpeL+K9xrbt88eEQ6Vo/483/QNc4aJRoKKuASdz+f2/MzLY9IKomS4nWaIodvrcoqIi6HQ6+Pk1LZ/w8/NDXl5ei+f069cP69evx7fffouPP/4Yer0e1157LbKzs03HTJkyBR9++CESExPxyiuvYPfu3bjhhhug0+lavObKlSvh5uZmegQHB3f6PRERkfkt/uQQRr6ciKySnjXvSacX8YuE+7GuFOLliMXX9QEAvPD9SVTU1ksajzntPJWPtMIquGgUmD0ipEPnyq/cl8V5WZ2SxvbtRM30uDXxUaNGYc6cOYiOjsb48ePx1VdfwcfHB++9957pmNmzZ+Pmm2/G4MGDMWPGDHz//fc4ePAgdu3a1eI1ly1bhrKyMtMjKyurm94NERFdTY1Wh+0n8lFcpcXqxHNSh9MhR7JLUVylhYtGYfpBXkr3jotAuLcTCirq8NZPPetz2RbjKtZfR4Z2qlwtLtzY/KL1qhdqHZteEDXX5STr7rvvhqura6fO9fb2hlwuR35+fpPn8/Pz272fSqlUIiYmBufPt94xKSIiAt7e3q0eo1ar4erq2uRBRETW4djFMuj0hqqJrw5fNP1A1xMYW7ePj/SxihlMGqUcz908EACwYW86TuSUSRxR1/2RUYLkC5egksswd3RYp65h3JeVlF5i+lqj9uOMLKLmOvQv/s8//4wBAwY02bP07rvvwtvbG2VlZRg4cCB+++23dl9PpVIhNjYWiYmJpuf0ej0SExMxatSodl1Dp9Ph2LFjCAgIaPWY7OxsFBcXt3kMERFZp5SsS6Y/6/Qi/vNLz2lDnnjKOkoFrzQu0gc3DgmAXgSe+eY49D08qViz27CKdWtsEHxdNFc5umUDA13hrFagvLYBp7gvq0NEUTQlWSwXJLqsQ0nWqlWrsHDhwhZXetzc3HDffffhzTff7FAAS5cuxdq1a7Fx40acOnUKixYtQlVVlanb4Jw5c7Bs2TLT8c8//zx27NiBtLQ0HDp0CHfffTcuXLiABQsWADA0xXjsscewf/9+ZGRkIDExEdOnT0efPn2QkJDQodiIiEh6KVmlAIApAw0VDl/3kNWs7EvVOJ1XAZkATIi0niQLAJ65cQCcVHIcyizF58k9t0T+fEEFdp7KhyAAC8ZGdPo6CrkMsaGGQcScl9UxRZVaVNY1QBAM+/6IyKBDSdaRI0faHOo7efJkJCcndyiAWbNm4fXXX8fy5csRHR2NlJQUbNu2zdQMIzMzE7m5l7sgXbp0CQsXLkT//v0xdepUlJeXY+/evRgwYAAAQC6X4+jRo7j55psRGRmJ+fPnIzY2Fr/99htnZRER9UApmaUAgHuuDcN1/Xyg04v498/Wv5r1c2PDi9hQD3g4qSSOpil/Nw0emRQJAFj542mUNM446mneb9yLNXmAX5dnfxlLBg+kcV9WRxhXsYLcHaBWyCWOhsh6dGh3aH5+PpRKZesXUyhQWFjY4SCWLFmCJUuWtPjan5tVvPXWW3jrrbdavZaDgwO2b9/e4RiIiMj65JfXIqesFjIBGNLLDQ/HR+KXM4X4JuUi/n59H6veA3K5VLD7BxC3x9xrw/BFcjZO51Xg1W2n8a9bh0gdUofkl9fi68MXAQD3mWGIcFyEoflFUkYJ9HoRMpltzRGzlPSiSgBsekH0Zx1ayQoKCsLx48dbff3o0aPc90RERGZzuHEVK9LPBU5qBYYGu+P6KF/o9CJW/2y93fGq6hqwL9WwIhJvRfuxrqSQy/DijEEAgE0Hs3Ao89JVzrAu6/eko14nYkSYJ64J8ejy9QYHucFRJUdpdT3O5FeYIUL7kF5kGKvA/VhETXUoyZo6dSqeeeYZ1NbWNnutpqYGK1aswLRp08wWHBER2TfjfqzoYHfTcw/H9wUAfHP4oqlUydr8dq4IWp0eIZ6OXS5js6RhYZ64Y1gvAMBTXx9HQw8Z+FxeW49P9mcCAO4b3/m9WFdSXrkviyWD7WZcybLmVWUiKXQoyXr66adRUlKCyMhIvPrqq/j222/x7bff4pVXXkG/fv1QUlKCp556ylKxEhGRnTF2FowJcTc9N6SXOyZG+UIvAv+20tWsn08bWrdP7O8LQbDusrMnb+gPd0clTuWW45lvT0AUrb/b4KcHMlFR14C+vs64rp/5VgpN+7LY/KLdMhpXslguSNRUh5IsPz8/7N27F4MGDcKyZcswc+ZMzJw5E//85z8xaNAg/P7776aGFURERF2h04s4mm2Y4xQd3LQc7KErVrPSCiu7Pba26PUifj5t2J88Mcr6vyd6Oqnw6q1DIBOAT5My8baVD3yua9Bh/Z50AIbhyubcO3V5KHFJj0g2pabXi0gv5iBiopZ0eDJiaGgotm7diqKiIhw4cAD79+9HUVERtm7divDwcEvESEREduhsfgWqtTo4qeTo49u05G5IL3fE9zesZv3HyjoNHr1YhqLKOrioFRjR+EO7tZs80B/PTzfsz1q18xw+OZApcUSt+zYlB/nldfBzVWN6dJBZrz2klzs0ShlKqrQ4V2Bdybs1yimrgbZBD6VcQJC7g9ThEFmVTo+f9/DwwPDhwzFixAh4eHR9wykREdGVjPuxhga7Q97CasVDEw0tyL9JuYhUK1rNSjxlKBUcF+kDlaLT32a73d0jQ/Hg9X0AAE9/cww7TuRJHFFzer1oats+f0y42T+/KgX3ZXWEsVQwxNMRCnnP+Von6g78G0FERFbJOB/ryqYXVxrcyw3x/f2sbjVrZ2Pr9uujrLOrYFsemRSJWcOCoReBv396GH9kWNfepJ9PF+B8QSVc1ArcOSLEIveICzfsy9rPfVlXxfbtRK1jkkVERFbpcGPTi9aSLOByp8FvrWQ1K6e0BqdyyyEIwHU9MMkSBAEvzRyEiVG+qGvQY/7GP3C+wHrama/ZnQoAuGtkKFw0rc/t7ArTvqy0Yu7Luoq0Iu7HImoNkywiIrI6FbX1pj0x0Vd0FvyzQUFumDTAsJr1byto2JB42rCKdU2IBzydVBJH0zkKuQz/+cs1iAlxR1lNPeasS0JeWfPRLd3tj4wS/HHhElRyGeaNDrPYfYYGu0OlkKGoUovUQuscEWAtMkxJlvWOKSCSCpMsIiKyOseyyyCKQJC7A3xdNG0e+9BEw2rWliM5OC9xs4KfT11u3d6TOajkWH/PcET4OCGnrBb3rE9CWU29pDG917gXa2ZMEPxc2/6a6AqNUo5rGhP7A+ncl9UW45y6MG9HiSMhsj5MsoiIyOocNg4hbmMVy6jJapaEc7OqtQ3Yk2r4oTy+v/W3br8aDycVNs4bAV8XNc7kV2Dhh3+gtl4nSSznCyrx00lDArtwnHmGD7fFtC8rjfuyWlOv0yPrUg0AIIIrWUTNMMkiIiKrc7ix6UVMG/uxrmQNq1m/nyuCtkGPXh4O6OtrGz90Bns6YsO8EXBRK5CUXoJHNqdAp+/+fUprG1exJg3wa9bO3xLiIrgv62qySqqh04twUMrh56qWOhwiq8Mki4iIrIooiqb27W01vbjSoCA3TB7gB1HC1ayfG/djxff3gyCYb0Cu1AYEuuK9ObFQyWX48XgenvvuRLcmHvnltfj68EUAwP3jLb+KBRj21KnkMhRU1CGjuLpb7tnTXC4VdLKpr3cic2GSRUREVuViaQ2KKuugkAkYFOTW7vMeir9yNat7O+Lp9aKp6UVPbN1+Ndf29sabs4ZCEIAP913Af3eldtu9P9iTAa1Oj2GhHogN7Z7hzhql3JTgc15Wy4xJVgQ7CxK1iEkWERFZFeMqVv8AV2iU8nafNzDQDQkDDatZqxO7d27W8ZwyFFbUwUklN5Wa2ZppQwKxfNoAAMBr28/g8z+yLH7Pitp6/N/+CwCA+8b3tvj9rmT8/7ifSVaL2PSCqG1MsoiIyKocvsoQ4rY8NDESAPDd0Rycy+++1SzjAOJxkT5QK9qfGPY080aH4/7GZOfJr47hl8bVO0v5NCkTFXUN6O3jhIndvEJobH5xIL2E+7JakM727URtYpJFRERWpaP7sa40INAVUwb6G1azfu6+1azExtbttlgq+GdPTOmHW64Jgk4v4oH/O2T6/2Vu2gY91v2eDgC4b1xvyGTdu+/nmlB3KOUCcstqkVVS06337gkyOIiYqE1MsoiIyGpoG/Q4frEMABDTjvbtLTHuzfr+aA7OdsNqVl5ZLU7klEMQgOvsIMkSBAGv3DoE4yJ9UFOvw982HERaofk7On6bchH55XXwdVFjekyg2a9/NY4qBYb0cgcA7Oe8rCZqtDrkNA6oZpJF1DImWUREZDVO55WjrkEPNwdlp3946x/gihsGNa5mJVq+02DiacMqVnSwO7yd7aOVtVIuw7t3XYMhvdxQUqXFnPVJKKioNdv19XoR7ze2bf/bmHDJSjDjwrkvqyUZxYZVLDcHJTwclRJHQ2SdmGQREZHVMJaeDQ1271Jb6Acb52b9cCzX4qtZP5+63LrdnjipFVg/dzhCvRyRfakGc9cfREVtvVmu/cuZApwrqISzWoG/xIWY5ZqdERfRuC+LQ4mbuLJUkO3biVrGJIuIiKxGSgeHELfmytWsty24mlWj1eH380UA7GM/1p95O6vx4d9GwNtZhZO55bj/42TUNei6fN33dhtWse6KC4GrRrqVkmGhHpDLBFwsrUFWCedlGaVxPxbRVTHJIiIiq2FqetHJ/VhXMu7N2nosF2fyLLOated8Eeoa9Ahyd0CUv4tF7mHtQr2c8MHcEXBSybHnfDEe/fwo9PrOd+NLvnAJSRklUMoFzBsdbsZIO85JrcDgxlltB9K5mmWUziSL6KqYZBERkVUordaafkMe3dhwoCui/F0xdbBl92YZBxBP7O9r12VTg3u5Yc1fY6GQCfjuSA5e3nqq09d6/1fDoOMZ0UHwd9OYK8ROM87L4lDiy9hZkOjqmGQREZFVMK5ihXk5wsNJZZZrGudm/WCB1SxRFPHzaftp3X41Y/v64PXbhwIA/vd7OtY2Nq7oiNTCSuw4afic3jsuwqzxddbIiMvzssiAK1lEV8cki4iIrIIxyYoJ8TDbNfv5u+DGwQEAzL+adSKnHPnldXBUyU0/iNu7GTFB+OfUKADAS1tP4ZvDFzt0/v9+S4MoAvH9fdHXzzrKL4eFekAmAJkl1cgp5bysspp6FFdpAQBhTLKIWsUki4iIrEJXhhC35cGJfSEIhtWs03nlZrvuzsYBxGP6eEOjlKbFuDVaODYC88cY9lI9+vkR/Hq2sF3nFVTU4stkQ1J23/jeFouvo1w0Sgwy7ctiyaCxVNDHRQ1ntULiaIisF5MsIiKSnCiKFkuy+vm7YKoFVrMS7bR1+9UIgoCnpvbHTUMD0aAXsejjZNOA6bZs2JMBrU6Pa0LcMSzUfKuZ5mCcl8VW7iwVJGovJllERCS5jOJqlFbXQ6WQoX+Aq9mv/1DjatbWY3k4ldv11az88loca0wcruN+rGZkMgGv3z4Eo/t4oUqrw9wPknChcYBtSyrrGvDR/gsADKtY1tZEhPuyLjMmWRFMsojaxCSLiIgkl5J1CQAwKNAVKoX5vzVF+pl3b9bPjV0Fhwa7w8dF3eXr2SK1Qo41d8diQIAriiq1uGd9Eooq61o8dlNSJipqGxDh7YRJVrgyOCzME4JgSDDyy2ulDkdSxiSL+7GI2sYki4iIJGccQhwdbLkyMeNq1o/Hu76aZSoV5CpWm1w0SmyYNxy9PByQUVyNv204iKq6hibHaBv0WPd7OgBDR0GZzLpWsQDAzUGJAY0rrPvtvJU7ywWJ2odJFhERSe6wGYcQt6avnwumDQkEALy9s/OrWbX1Ovx+3tDM4fr+TLKuxtdVgw//NgKeTioczS7Dov87hHqd3vT6d0dykFtWCx8XNWbEBEkYadtYMmjYO5nBckGidmGSRUREkqqt15lWlmLM3PTizx68vg8EAdh2Ig8nczq3mrU3tQi19XoEumlMqxvUtggfZ6y7ZxgclHL8erYQT3x5FKIoQhRFvNc4fHje6DCr7tJ4ufmF/a5kFVVqUVHXAEEAgj0dpQ6HyKoxySIiIkmdyClHvU6Et7MKvTwcLHqvJqtZiWc7dQ1jqeD1/X2trkGDNYsJ8cB/77oGcpmArw5dxKvbz2DXmUKcza+Ek0qOu+JCpQ6xTSPCDfuyUgurUFBhn/uyMhqblwS5O1h1QkxkDZhkERGRpK5s3d4dSctDEw2rWdtP5ONEztVbi19JFEVT04uJUdbXoMHaXRfli3/dMhgA8O6uVDz2xREAwF/iQuDmoJQytKtyd1ShX+OA5CQ7LRlML+R+LKL2YpJFRESSOpxp6Cxo7vlYrenj64KbOrk362RuOXLLauGglGNUby9LhGfzbh8WjMcS+gEwlJ8pZAL+1ji82NqZ9mXZ6bysNDa9IGo3JllERCQp40pWTEj3DaB9sLHT4I6T+e0alGtkLBUc3ceb5VJd8MCE3rhnlKE88LbYXghws2yZqLmMjGjcl5Vun/uyMphkEbUbkywiIpJMYUUdsi/VQBCAIb3cuu2+fXydcfNQw2pWR+ZmJZ7KBwDEs6tglwiCgGdvHogtS0bj2ZsHSh1Ou40IN6xknc2vRHErM79sGWdkEbUfkywiIpKMcRWrj48zXDTduyfn79f3hawDq1kFFbU4km047nrOx+oyQRAwpJd7j1oR9HSy331Zer1oanzB9u1EV8cki4iIJJOS1b37sa505WrW2+1YzfqlseHFkF5u8HXVWDQ2sl5xppJB+0qycstrUdegh1IuIMi9Z5R3EkmJSRYREUlGiv1YV/r7RMNq1k/tWM0y7sdiV0H7FtdYMrjfzuZlGTsLBns6QiHnj49EV8O/JUREJAmdXsSRLENiI8VKFgD09nHG9OggAMCqNjoN1tbr8Nu5IgDARO7HsmsjGocSn86rwKUqrcTRdJ/0okoALBUkai8mWUREJInUwkpU1jXAQSlHpJ+zZHH8/fo+kAnAzlOtr2btSytGTb0O/q4aDAx07eYIyZr4uKjRx9fw9ZqUYT8lg+lF1QDYWZCovZhkERGRJFIySwEAg3u5SVp+FOHjjBmm1ayzLR7zc2Op4PX9fbtlYDJZt7jG1Sx7mpdlXMliZ0Gi9mGSRUREkjhs2o/lLmkcALDEtJpVgGPZTVezRFE0tW6fyK6CBCAuwv72ZWUUcyWLqCOYZBERkSRMTS8k2o91pbZWs07nVSCnrBYapQyj+3hLER5ZmZGNK1mn8spRVl0vcTSWV6/TI7PEkGRFeEtX2kvUkzDJIiKibldV14AzeeUAgOhgaToL/pmx02Di6QIczS41PW9cxRrd27tHzXQiy/F11SDC2wmiCBy0g31ZWSXV0OlFOCjl8HNVSx0OUY9gFUnWO++8g7CwMGg0GsTFxSEpKanVYzds2ABBEJo8NJqm80pEUcTy5csREBAABwcHxMfH49y5q89AISKi7nHsYhn0IhDgpoG/m3XMnAr3dsKMGMNq1ttXdBrcaWzd3p+t2+myy/OybL9k0DiEOMzbiXsSidpJ8iRr8+bNWLp0KVasWIFDhw5h6NChSEhIQEFBQavnuLq6Ijc31/S4cOFCk9dfffVVrF69GmvWrMGBAwfg5OSEhIQE1NbWWvrtEBFROxhLBaVq3d6aB6/vC7lMQOLpAhzJKkVhRR2ONK5qXc/9WHSFy/OybH8lK61xRla4t6PEkRD1HJInWW+++SYWLlyIefPmYcCAAVizZg0cHR2xfv36Vs8RBAH+/v6mh5/f5d8uiqKIVatW4emnn8b06dMxZMgQfPjhh8jJycE333zTDe+IiIiuxthZ0NqSrDBvJ9PerLcTz+GXMwUQRWBQkKvVrLiRdTCuZJ3IKUN5rW3vy0ovMiZZbHpB1F6SJllarRbJycmIj483PSeTyRAfH499+/a1el5lZSVCQ0MRHByM6dOn48SJE6bX0tPTkZeX1+Sabm5uiIuLa/WadXV1KC8vb/IgIiLLOZx1CYD1JVmAYW6WXCbg59MFeP/XNADAxCiWClJTAW4OCPVyhF4EkjMuSR2ORRnLBcPZ9IKo3SRNsoqKiqDT6ZqsRAGAn58f8vLyWjynX79+WL9+Pb799lt8/PHH0Ov1uPbaa5GdnQ0ApvM6cs2VK1fCzc3N9AgODu7qWyMiolbkltUgv7wOcpmAwb3cpA6nmTBvJ8xs3Jt1vsAwG2hif5YKUnPGeVn7bXxfVjrLBYk6TPJywY4aNWoU5syZg+joaIwfPx5fffUVfHx88N5773X6msuWLUNZWZnpkZWVZcaIiYjoSsZSwX5+LnBUKaQNphXG1SwA8HVRY1Cg9SWDJD172JdVo9Uhp8ywp50rWUTtJ2mS5e3tDblcjvz8/CbP5+fnw9/fv13XUCqViImJwfnz5wHAdF5HrqlWq+Hq6trkQURElmFqemEFQ4hbE+rlhFsaV7MmDfCDTMaOatSccV/W8YtlqKxrkDgay7hQYljFcnNQwsNRKXE0RD2HpEmWSqVCbGwsEhMTTc/p9XokJiZi1KhR7bqGTqfDsWPHEBAQAAAIDw+Hv79/k2uWl5fjwIED7b4mERFZzmErbXrxZ89NH4gXZwzC4wlRUodCVqqXhyN6eThApxeRfME292UZSwXZvp2oYyQvF1y6dCnWrl2LjRs34tSpU1i0aBGqqqowb948AMCcOXOwbNky0/HPP/88duzYgbS0NBw6dAh33303Lly4gAULFgAwdB58+OGH8eKLL2LLli04duwY5syZg8DAQMyYMUOKt0hERI0adHocu1gGALjGileyAMBRpcDdI0Phxt/eUxsulwza5r6s9MamFxHsLEjUIZIXw8+aNQuFhYVYvnw58vLyEB0djW3btpkaV2RmZkImu5wLXrp0CQsXLkReXh48PDwQGxuLvXv3YsCAAaZjHn/8cVRVVeHee+9FaWkpxowZg23btjUbWkxERN3rTH4Faup1cNEoEMH9HWQDRkZ44stD2Thgq0lWIdu3E3WGIIqiKHUQ1qa8vBxubm4oKyvj/iwiIjP6eP8FPP3NcYzp442PF8RJHQ5Rl2WVVGPsq79AIRNw9NnJVtvMpbNue3cv/rhwCavvjMHNQwOlDodIEp3JDSQvFyQiIvthanph5fuxiNqrl4cDAt00aNCLOHShVOpwzC6D5YJEncIki4iIuo0xyYqx8v1YRO0lCALiImxzX1ZZTT2KKrUADI0viKj9mGQREVG3KKupNw335UoW2ZKRja3cD9jYUOKMIsMqlo+LGs5q2yqDJLI0JllERNQtjmaXAgCCPR3g5ayWNhgiMzJ2GDySVYbaep3E0ZiPsVSQTS+IOo5JFhERdYuUxvlYMcEe0gZCZGahXo7wc1VDq9PjUKbtzMtKM3YW9GKSRdRRTLKIiKhbsOkF2SpBEDDStC+rROJozMe0kuXDJIuoo5hkERGRxYmieDnJYtMLskHGkkFbmpeVXsRyQaLOYpJFREQWl1VSg+IqLZRyAQMCOH+QbE9cY/OLw1mlNrEvSxRFDiIm6gImWUREZHGHswz7VAYEukGjlEscDZH5RXg7wdtZDW2DHkcaV217suIqLSrqGiAIQIino9ThEPU4TLKIiMjiTPOxuB+LbJRhX5ZhNcsW9mUZSwWD3B34ixGiTmCSRUREFsemF2QPjEOJbWFeFksFibqGSRYREVlUXYMOJy6WA2CSRbZtZLhhJetQ5iXUNfTsfVnpnJFF1CVMsoiIyKJO5VZAq9PDw1GJUC/u7SDb1cfXGV5OKtTW63E0u0zqcLrEuJIVxhlZRJ3CJIuIiCwqpXE4a3SwOwRBkDgaIssRBMHUZbCnt3I3tW/njCyiTmGSRUREFnV5P5aHtIEQdQPTvKz0ntv8Qq8XTYOII1guSNQpTLKIiMiiDnMIMdkR40rWHxmXUK/TSxxN5+SW16KuQQ+FTECQu4PU4RD1SEyyiIjIYkqqtLhQXA0AiO7lLm0wRN0g0tcFHo5K1NTreuy+rIzGUsEQL0co5PxRkagz+DeHiIgsxjiUNcLHCW6OSmmDIeoGMpmAEY1dBntqK/e0IpYKEnUVkywiIrKYw5yPRXbItC+rhw4lZmdBoq5jkkVERBZzuLGzYEwIm16Q/RjZOJT4j4wSNPTAfVnGphfsLEjUeUyyiIjIIvR60VQuGMOVLLIjUf4ucHNQokqrw/GccqnD6TBT+3aWCxJ1GpMsIiKyiPTiKpTXNkCtkKGfv4vU4RB1G5lMwPCwnjkvq16nR2aJoVkNkyyizmOSRUREFnE4sxQAMDjIDUp2KCM7M9I4lLiHzcvKvlQDnV6Eg1IOPxeN1OEQ9Vj8rkdERBaRkmXcj+UubSBEEjDuyzqYXgKdXpQ4mvZLL6oEAIR6OUImEySOhqjnYpJFREQWkWLqLMimF2R/+ge4wkWjQEVdA072oH1Z6UWGUsEINr0g6hImWUREZHY1Wh1O51YAAKK5kkV2SH7lvqweNC/LuJLF/VhEXcMki4iIzO54Thka9CJ8XNQIdOO+DrJPxn1Z+3vQvCxjZ0HOyCLqGiZZRERkdimNTS9igt0hCNzXQfbJOJQ4Kb24x+zLymC5IJFZMMkiIiKzM+3HYqkg2bGBga5wVitQXtuA03nWvy+rtl6Hi6U1AIBwb2eJoyHq2ZhkERGR2V1ueuEuaRxEUlLIZYgNNTR+OdADSgYzig2lgq4aBTwclRJHQ9SzMckiIiKzKiivxcXSGggCMKSXu9ThEEnK2Mq9JzS/yGjcjxXu48wyX6IuYpJFRERmdbhxFaufnwuc1QppgyGSWNwVQ4n1Vr4vK60xyYpgZ0GiLmOSRUREZsVSQaLLBge5wVElR2l1Pc4WVEgdTpvSC9lZkMhcmGT1AOcLKqUOgYio3YydBZlkEQFKuQzDGudl/Xy6QOJo2mbckxXOzoJEXcYky4rV1uvw13UHMPmt3Uy0iKhH0OlFHM0uBQDEhHhIGwyRlbhhkD8A4PsjuRJH0jbjjKxwrmQRdRmTLCumUcqhUcqhF4E3dpyROhwioqs6V1CBKq0OTio5+viyBTQRAEwZ6A+FTMDJ3HKkFVrnL03La+tRVKkFAIR5O0ocDVHPxyTLyj2W0A8yAfjxeJ5pnwMRkbUylgoO6eUOuYzdyYgAwMNJhTF9vQEA3x+1ztUsY2dBHxc1XDRs307UVUyyrFyknwtuuaYXAOCVH09DFK27MxER2TcOISZq2bQhgQCA747kSBxJy1gqSGReTLJ6gIfj+0Ill2FfWjF+O1ckdThERK063LiSFcOmF0RNTB7oB5VchnMFlTiTZ31dBk1JFtu3E5kFk6weoJeHI/46KhQA8Or201Y/Z4OI7FNlXYOpRTVXsoiactUoMb6fDwDg+6PWt5plSrLYWZDILJhk9RCLr+sDZ7UCxy+W44dj1lnPTUT27Wh2KUQRCHJ3gK+LRupwiKzOtCEBAAwlg9ZW/m9Msjgji8g8mGT1EJ5OKtw7LgKAodNgvU4vcURERE0d5nwsojbF9/eDRilDRnE1TuSUSx2OiSiKpiQrgitZRGbBJKsHmT8mHN7OKmQUV+OzP7KkDoeIqAlj04sYlgoStchJrcD1Ub4AgO+sqGSwuEqLitoGCAIQ4sn27UTmwCSrB3FSK/D36/sCAN7eeQ41Wp3EERERGYiieLmzIFeyiFp1U2OXwe+P5FpNyaBxFSvQzQEapVziaIhsA5OsHubOESHo5eGAgoo6fLA3XepwiIgAADlltSisqINCJmBQkJvU4RBZreuifOGkkuNiaQ0OW8n8S5YKEpkfk6weRqWQ4R+TIwEA7+5KRWm1VuKIiIiAw5mXAAD9A1z5m3CiNmiUcsQP8ANgWM2yBmx6QWR+VpFkvfPOOwgLC4NGo0FcXBySkpLadd6mTZsgCAJmzJjR5Pm5c+dCEIQmjylTplggcmlMHxqEKH8XVNQ24N3dqVKHQ0SEFDa9IGo3Y8ngD8dyrGIsSwZnZBGZneRJ1ubNm7F06VKsWLEChw4dwtChQ5GQkICCgoI2z8vIyMCjjz6KsWPHtvj6lClTkJuba3p8+umnlghfEjKZgMen9AMAbNiTgdyyGokjIiJ7x/1YRO03NtIbLhoF8svrcDCjROpwOCOLyAIkT7LefPNNLFy4EPPmzcOAAQOwZs0aODo6Yv369a2eo9PpcNddd+G5555DREREi8eo1Wr4+/ubHh4eHpZ6C5K4rp8vRoR5oq5Bj9WJ56QOh4jsWL1Oj2MXywBwCDFRe6gVciQM9AcAfH9U2pJBvf5y+/ZwlgsSmY2kSZZWq0VycjLi4+NNz8lkMsTHx2Pfvn2tnvf888/D19cX8+fPb/WYXbt2wdfXF/369cOiRYtQXFzc6rF1dXUoLy9v8rB2giDgiRsMq1mf/ZGN1MJKiSMiInt1OrcCdQ16uDko+UMaUTvdNNRQMrj1WC4aJJx9mVdei7oGPRQyAb08HCSLg8jWSJpkFRUVQafTwc/Pr8nzfn5+yMvLa/Gc33//HevWrcPatWtbve6UKVPw4YcfIjExEa+88gp2796NG264ATpdyy3PV65cCTc3N9MjODi482+qG8WGeiK+vx90ehFv7DgjdThEZKdSsgxNL4YGu0MmEySOhqhnuLa3FzwclSiu0mJ/mnQlg8ZVrBAvRyjkkhc4EdmMHvW3qaKiAn/961+xdu1aeHt7t3rc7NmzcfPNN2Pw4MGYMWMGvv/+exw8eBC7du1q8fhly5ahrKzM9MjK6jmDfh9L6AdBALYey8MRK2kFS0T25TD3YxF1mFIuw5RBAQCA7yUcTJzGUkEii5A0yfL29oZcLkd+fn6T5/Pz8+Hv79/s+NTUVGRkZOCmm26CQqGAQqHAhx9+iC1btkChUCA1teVOexEREfD29sb58+dbfF2tVsPV1bXJo6fo5++CmTFBAIBXt5+WOBoiskfGphcxTLKIOuSmoYYk68fjedA2SFMyyM6CRJYhaZKlUqkQGxuLxMRE03N6vR6JiYkYNWpUs+OjoqJw7NgxpKSkmB4333wzrrvuOqSkpLRa5pednY3i4mIEBARY7L1I6ZH4SKjkMuw5X4zfzxVJHQ4R2ZGy6nqkFRp+SONKFlHHxIV7wcdFjbKaeuw5L833b3YWJLIMycsFly5dirVr12Ljxo04deoUFi1ahKqqKsybNw8AMGfOHCxbtgwAoNFoMGjQoCYPd3d3uLi4YNCgQVCpVKisrMRjjz2G/fv3IyMjA4mJiZg+fTr69OmDhIQEKd+qxQR7OuKukSEAgFe2nbaKmRtEZB9SsksBAGFejvBwUkkbDFEPI5cJmDrIULnznUQlgxksFySyCMmTrFmzZuH111/H8uXLER0djZSUFGzbts3UDCMzMxO5ue1vbyqXy3H06FHcfPPNiIyMxPz58xEbG4vffvsNarXaUm9Dckuu6wMnlRzHLpbhx+MtNw0hIjI3DiEm6hpjl8EdJ/JRW99ygy5LqdfpkVlSDYArWUTmppA6AABYsmQJlixZ0uJrrTWrMNqwYUOTjx0cHLB9+3YzRdZzeDmrsXBcBFbtPIfXd5zB5IF+ULJLEBFZmLGzIJMsos65JsQDAW4a5JbVYvfZQtP8rO6QfakGDXoRGqUMfi6abrsvkT3gT+E2ZMHYCHg5qZBeVIXP/8iWOhwisnGiKF5uehFiWwPfibqLTCbgxsHGLoPdO5jYWCoY5uXE8QtEZsYky4Y4qxVYcn0fAMDbiWdRo+3esgMisi8XiqtxqboeKoUM/QN6TldWImtjLBnceTIf1dqGbruvsX17BEsFicyOSZaN+UtcCHp5OCC/vA4b9mZIHQ4R2TDjKtbAQFeoFPx2QtRZQ3q5IcTTETX1Ovx8uqDb7pteVAnAsJJFRObF74o2Rq2QY+mkSADAu7vOo6y6XuKIiMhWXZ6PxVJBoq4QBAE3DmksGTzSfSWDGUWNTS84I4vI7Jhk2aDp0UHo5+eC8toGvLu75QHNRERddTizselFiLu0gRDZgJuGGEoGfzlTgIra7vkFaTrLBYkshkmWDZLLBDw+pR8A4IM96cgrq5U4IiKyNbX1OpzMLQcAxLCzIFGX9Q9wQYSPE+oa9Nh5Kt/i96ut1+FiaQ0AlgsSWQKTLBt1fZQvhoV6oK5Bj7cTz0kdDhHZmJO55ajXifByUqGXh4PU4RD1eIIgYFrjalZ3lAxeKDaUCrpqFPDkIHEis2OSZaMEQcATN0QBAD77IwtphZUSR0REtuRw4xDimBB3CAJbPxOZw02N+7J+PVdo8T3VxqYX4T7O/DtMZAFMsmzY8DBPTIzyhU4v4o0dZ6UOh4hsiLHpBYcQE5lPXz8XRPm7oF4nYvuJPIveK93Y9MLL0aL3IbJXTLJs3GNT+kEQgB+O5eJodqnU4RCRjUjJamx6wc6CRGY1rXE167ujORa9j2kly9vZovchsldMsmxclL8rZkYHAQBe235G4miIyBYUVdYhq6QGggAMCXaTOhwim2Lcl7U3tRjFlXUWu4+xs2CYN1eyiCyBSZYdeGRSJJRyAb+dK8Ke80VSh0NEPVxK436sPj7OcNUopQ2GyMaEeTthcJAbdHoRPx63XMmgsVwwgitZRBbBJMsOBHs64q64UADAK9tOQxRFiSMiop6M+7GILMtYMvi9hUoGy2vrUdS4SsaVLCLLYJJlJ5Zc3wdOKjmOZpdZ9DdjRGT7TEkWhxATWcSNjUnWgfQSFJSbf9ZlRmOpoLezGi5cjSayCCZZdsLbWY0FYyMAAK9vP4MGnV7iiIioJ9LrRRzhShaRRfXycMQ1Ie4QRUPjKnMz7seK8OYQYiJLUUgdAHWfBWPD8dH+C0grqsLnydm4c0SI1CERkRWr0epwNr8CZ/IqcDqvAmfyy3EmrwIVdQ1wUMrRz89F6hCJbNa0IYE4lFmK74/mYt7ocLNe25hkhTPJIrIYJll2xEWjxOLr+uCF709i1c6zmBkTBI1SLnVYRGYliiJ2ny1ElL8r/N00UofTI+j0IjKKqy4nU3mGZOpCSTVa2sIpCMBf4kKgkLMYgshSbhwSgBd+OInkC5dwsbQGQe4OZrv25c6CTLKILIVJlp25e2QI1v+ejoulNdi4NwP3je8tdUhEZvVNykU8svkIgj0d8OND4+Cs5j9zRqIoorCirjGRurw6dS6/EnUNLZcQezur0M/fBf38XBHl74J+/i7o6+cMRxU/r0SW5OeqwYgwTxxIL8EPR3Nw7zjzfb/O4EoWkcXxu6SdUSvkeGRSJB79/Aj+uysVs0eEwM2Bm17JNtTW6/DaNsM8uKySGry89RRenjlY4qikUVXX0LTUL68Cp/PKcam6vsXjHZRyRPo5GxIq/8sJlbezupsjJyKjaUMDcSC9BN8fzTVbkiWKItKMe7J8mGQRWQqTLDs0MyYI7/+airP5lXhvdyoenxIldUhEZrF+Tzpyymrh4ajEpep6fHIgE5MH+GFCP1+pQ7OYBp0eGcVVTVen8iqQWVLd4vEywVAiFNW4OtXP3wVR/i4I9nSEXCZ0c/RE1JYbBvljxbfHcTS7DBeKqxDq1fWkqKRKi4raBggCEOLJ9u1ElsIkyw7JZQIeS4jCwg//wPo96bjn2jD4uXLvCvVsxZV1ePeXVADAM9MG4Gh2GTbszcATXx7FjofHw83R9lZsvz6cjae+Po5qra7F131c1I3JlGFVqn+AK/r4OnMvJlEP4e2sxug+3vjtXBG+P5qLxdf16fI1jfuxAt0c+G8BkQUxybJT8f19ERvqgeQLl7A68RxestOSKrId//75PCrqGjAgwBUzooNww6AA/Hq2EGlFVVix5ThWzY6ROkSzOpFThie+PAZtgx6OKjki/VxMJX6G1SlXeDqppA6TiLpo2pAA/HauCN8dyTFLkpXG/VhE3YKtoeyUIAh4orFMcNPBLNNvtoh6ooyiKny8/wIA4J9T+0MmE+CgkuONO4ZCJgDfpOTgRwvMmpFKVV0D/v7JYWgb9Lg+yhfHn03AN4tH41+3DsG80eG4trc3EywiG5Ew0B8KmYDTeRU4X1DR5eux6QVR92CSZcdGhHviun4+0OlFvLHjjNThEHXaq9tPo0EvYnykD8b09TY9HxPigUUTDJvF//n1MRRW1EkVotmIooinvzmOtKIq+Ltq8PrtQyHjXioim+XuqMK4SB8AwHdHuv7LIs7IIuoeTLLs3ONToiAIwPdHc3Esu0zqcIg6LPnCJWw9lgeZACyb2ryJy0MTIxHl74JL1fVY9tUxiC0NfupBvkjOxteHL0ImAKvvjOGKFZEdmDYkAADw/dGcLv8bxiSLqHswybJz/QNcMX1oIADDagBRTyKKIl7eegoAcFtsL0T5uzY7RqWQ4a1Z0VDKBew8lY8vD13s7jDN5lx+BZZ/ewIAsHRSJEaEe0ocERF1h0kD/KBSyJBaaOgk2ln6xsHjAJMsIktjkkVYOqkflHIBv50rwt7zRVKHQ9Ru20/kIfnCJWiUMiyd1K/V4/oHuOLh+EgAwHNbTiCntKa7QjSbGq0OSz45jJp6Hcb08caiCV3fAE9EPYOLRonr+hlLBnM6fZ288lrU1uuhkAno5eFgrvCIqAVMsgghXo74y4gQAMAr28/0+HIqsg/1Oj1eaRw8vHBsBPzd2h5DcN+4CMSEuKOirgGPf3EUen3P+jp//vsTOJNfAW9nNd6cNZQzrYjszLQhhqqT74/mdvr7tLHpRYinIxRy/ghIZEn8G0YAgCXX94WjSo4jWaXYfiJP6nCIrurTpEykF1XBy0mFe8dFXPV4hVyGN24fCo1Sht/PF+HjAxe6IUrz2HIkB58mZUEQgFWzouHrwrl2RPZmYn9fOCjlyCypxrGLndtDzfbtRN2HSRYBMAwtXTAmHADw6vYzaNDpJY6IqHUVtfV4e+c5AMDD8X3homnfoOEIH2c82Ti6YOXW0z1idEFGURX++dUxAMDiCX2adE8kIvvhqFJgYn9fAJ0vGWTTC6LuwySLTBaOi4CHoxJphVX48lC21OEQtWrN7lQUV2kR4e2E2Y2lru01Z1QYru3thZp6HR79/Ah0Vlw2WNegw5JPD6GyrgHDwzzwcHxfqUMiIgkZSwZ/OJrbqZJnY7lgGJMsIotjkkUmLhqlaZr8Wz+dQ229TuKIiJrLLavB/35LBwA8cUMUlB3cVyCTCXj1tiFwViuQfOES3v81zRJhmsXKradx/GI5PByVWH1nDPdQENm5Cf184KxWIKesFoezLnX4fONKVgSTLCKL43dsauLukaEIdNMgr7wWz245gRotEy2yLm/sOIu6Bj2Gh3lg8gC/Tl2jl4cjlt80AADw1k9ncTqv3JwhmsX2E3nYsDcDAPDGHUMR4MZOYET2TqOUY1Ljv3sdHUzcoNMjs6QaAFeyiLoDkyxqQqOU44kbDHtWNh3MwpS3f8XeVLZ1J+twKrfcVMr6z6n9IQid77B3e2wvTIzyhVanx9LNR6BtsJ59iNmXqvHY50cAAAvHhuP6qM4lk0Rke24aahhM/MOx3A6VO2dfqkGDXoRGKYO/K5vnEFkakyxqZnp0EP43Zxj8XTW4UFyNv6w9gGVfHUVZTb3UoZGdW/njaYgicOOQAMSEeHTpWoIgYOWtg+HhqMTJ3HL8++dzZoqya+p1ejz46WGU1zZgaLA7HkuIkjokIrIiY/r4wM1BicKKOiSll7T7PGOpYJiXE2QcAUFkcUyyqEXxA/ywY+k43BVnaCrwaVIWJr25m+3dSTK/nSvEr2cLoZQLeDyh9cHDHeHrosGLMwYDAP67KxUpWaVmuW5XvLHjLA5llsJFo8B/7oyBSsF/ponoMpVChoSBhtXt74+2v8sg27cTdS9+96ZWuWqUeGnmYGy6dyTCvZ1QUFGH+z5KxgP/l4yCilqpwyM7otOLeHnraQCGfYOhXub7IeHGIQG4aWggdHoR//gsRdKGL7vOFGDN7lQAwCu3DkGwp6NksRCR9bppqKHL4I/H89o9ciWDSRZRt2KSRVc1MsILPz40Fosm9IZcJmDrsTxMevNXfP5HVqenzhN1xNeHL+JUbjlcNAo8eL3525i/MH0gfFzUSC2swqvbzpj9+u2RX16LpZ8Z9mH9dWQopg4OkCQOIrJ+oyK84OWkQkmVFntTi9t1DmdkEXUvJlnULhqlHE9MicK3i0djUJArymrq8dgXRzFnfRKyGrsVEVlCbb0Ob+wwJD6Lr+sDDyeV2e/h7qjCq7cOAQCs35OOfe38ocVcdHoRD206jJIqLfoHuOKpG/t36/2JqGdRyGWYMsgfQPtLBplkEXUvJlnUIYOC3PDNA6Px5A1RUCtk+O1cESa/9Sv+91uaVQ91pZ5r/Z505JbVIsjdAXOvDbPYfa6L8sXs4cEAgMe+OILKugaL3evP/v3zOexPK4GjSo53/hIDjVLebfcmop7JWDK47XjeVbuj1tbrkFNWA4BJFlF3YZJFHaaQy3D/+N7Y9vA4jIzwRE29Di/+cAq3vLvXKucNUc9VXFmHd38x7FF6NCHS4snH09MGoJeHA7Iv1eDF709a9F5Ge1OL8HaiobPhSzMHIcLHuVvuS0Q92/AwT/i6qFFe24DfzhW2eeyF4mqIIuCqUcDTAtUARNQckyzqtHBvJ3yyYCRW3jIYLmoFjmSVYtrq3/HmjjOoa+AQY+q6f/98HhV1DRgY6IrpQ4Msfj9ntQKv3TYUgGFO3C+nCyx6v6LKOjy8KQWiaJjbNTOml0XvR0S2Qy4TTHs3vz/a9mDiK0sFuzJfkIjaj0kWdYlMJuDOESHY+Y/xmDzADw16Eat/Po8bV/+O5Avtn99B9GfpRVX4eP8FAIbBw90112VUby/8bXQ4AOCJL4+itFprkfvo9SKWfnYEBRV16OPrjOemD7TIfYjIdhlLBnecyGuzMyr3YxF1PyZZZBZ+rhq899dY/Peua+DtrML5gkrctmYfVnx7vFv3tpDteHXbaTToRUzo54PRfby79d6PT+mHCB/D2IJnvj1hkXu8/1safj1bCLVChnf+cg0cVQqL3IeIbNc1Ie4IcndAlVaHXWdaX3lPL6oEAIQxySLqNkyyyGwEwVC6sHPpeNwW2wuiCGzcdwEJb/3a5j/+RH+WfKEEPx7Pg0wAlt3Q/Z32NEo53rwjGnKZgO+O5HRo4Gd7JF8owWvbDR0Tn7t5IPr5u5j1+kRkHwRBwI1DDCWD37VRMphRZOgCzJUsou7DJIvMzt1RhddvH4qP5o9ALw8HXCytwdwPDuKRzSkoqbJM6RXZDlG8PHj49thgyRKQ6GB3PDChNwDgmW+Om20Ad2m1Fg9+mgKdXsTNQwMxq7GjIRFRZ9w0xFAymHgqH1WtVI6kNZYLRnizsQ5Rd7GKJOudd95BWFgYNBoN4uLikJSU1K7zNm3aBEEQMGPGjCbPi6KI5cuXIyAgAA4ODoiPj8e5c+csEDm1ZWxfH+x4ZBzmjwmHTDAMlJ305m58m3KRQ4ypVdtP5CH5wiVolDIsnRwpaSx/v74vBgS44lJ1PZZ9eazLX7eiKOKxL47iYmkNQr0c8dLMQdyETkRdMijIFaFejqit1yOxhWY9FbX1KKqsAwCEeTt2d3hEdkvyJGvz5s1YunQpVqxYgUOHDmHo0KFISEhAQUHb5WUZGRl49NFHMXbs2Gavvfrqq1i9ejXWrFmDAwcOwMnJCQkJCaitNc9voqn9HFUKPDNtAL56YDT6+bmguEqLhzalYMHGP5BTWiN1eGRl6nV6vLLNUEa3cGwE/Fw1ksajUsjw5qyhUMllSDxdgM+Ts7t0vQ17M/DTyXyo5IZ9WC4apZkiJSJ7JQgCpjWWDH5/pHlps7FU0NtZzX9ziLqR5EnWm2++iYULF2LevHkYMGAA1qxZA0dHR6xfv77Vc3Q6He666y4899xziIiIaPKaKIpYtWoVnn76aUyfPh1DhgzBhx9+iJycHHzzzTcWfjfUmuhgd3z39zFYOinS9APr5Ld+xUf7L0DPIcbU6JMDmUgvqoK3swr3je8tdTgAgCh/VzwyybCi9vx3J5F9qbpT1zmWXYaVjWWQ/5wahUFBbmaLkYjsm7HL4K4zhSivrW/yWlpj04sI7sci6laSJllarRbJycmIj483PSeTyRAfH499+/a1et7zzz8PX19fzJ8/v9lr6enpyMvLa3JNNzc3xMXFtXrNuro6lJeXN3mQ+akUMjw4sS9+eHAMYkM9UFnXgGe+OY7Z7+9HamGl1OGRxMpr601DeR+Kj4Sz2nq67d07LgLXhLijsq4Bj39xtMO/GKiorceSTw9Bq9Nj8gA/3HNtmGUCJSK71M/PBX18naHV6fHTifwmrxlXslgqSNS9JE2yioqKoNPp4Ofn1+R5Pz8/5OXltXjO77//jnXr1mHt2rUtvm48ryPXXLlyJdzc3EyP4GBuRLekvn4u+Py+UXju5oFwUsmRlFGCG97+De/8ch71Or3U4ZFE1uxKRUmVFhE+TphtZc0g5DIBb9wRDQelHHtTi/Hhvox2nyuKIpZ9dQwXiqsR5O6A124byn1YRGRWTUoG/9QN1di+PZxNL4i6leTlgh1RUVGBv/71r1i7di28vc03N2fZsmUoKyszPbKyssx2bWqZTCbgnmvDsP2RcRgf6QNtgx6vbT+D6f/Zg3P5FVKHR90sp7QG635PBwA8OSUKSrn1/dMU7u2EZVOjAAD/2nYaae1cfd10MAvfH82FXCZg9Z0xcHPknggiMr9pjV0GfztXhEtXdPLlIGIiaUj6k4y3tzfkcjny85subefn58Pf37/Z8ampqcjIyMBNN90EhUIBhUKBDz/8EFu2bIFCoUBqaqrpvPZeEwDUajVcXV2bPKh79PJwxIZ5w/HWrKHwcFTiZG45pv37d2zYk84OhHbkzZ/Ooq5BjxFhnpg0wO/qJ0jk7rhQjO7jhdp6Pf7x+RE0XGXl9XReOZ7dYhhm/FhCP8SGenRHmERkh/r4OqN/gCsa9CK2nzBU7oiiyCSLSCKSJlkqlQqxsbFITEw0PafX65GYmIhRo0Y1Oz4qKgrHjh1DSkqK6XHzzTfjuuuuQ0pKCoKDgxEeHg5/f/8m1ywvL8eBAwdavCZJTxAEzIzphe2PjMOEfj6oa9Dj2e9O4p4PDqKgnB0hbd3JnHJ8ecjQtW/Z1CirLqWTyQS8ettQuKgVOJxZivd+TWv12GptA5Z8chh1DXqMj/TBvWMjWj2WiMgcLpcMGgYTl1RpUV7bAEEAQr24J4uoO0lek7N06VKsXbsWGzduxKlTp7Bo0SJUVVVh3rx5AIA5c+Zg2bJlAACNRoNBgwY1ebi7u8PFxQWDBg2CSqWCIAh4+OGH8eKLL2LLli04duwY5syZg8DAwGbztMi6+Lpo8MHc4Xhh+kCoFTL8erYQCat+xbbjLe+lI9uw8sdTEEXgxiEBiAmx/pWeIHcHLL9pAABg1c6zOJnTcqOcFd+ewPmCSvi5qvHmHUMhk1lv8khEtsE4mHhvahEKK+pMq1iBbg7QKOVShkZkdyRv3zVr1iwUFhZi+fLlyMvLQ3R0NLZt22ZqXJGZmQmZrGO54OOPP46qqirce++9KC0txZgxY7Bt2zZoNNLO3KGrEwQBfx0VhlG9vfDQphScyCnH/R8n445hvbD8poFW1XGOuu7Xs4X47VwRlHIBTyRESR1Ou90W2wvbT+Rj56l8LP0sBVuWjIFKcfnfqa8OZePz5GzIBODt2THwclZLGC0R2YsQL0cM7eWGI9ll2HY815RYsVSQqPsJIje+NFNeXg43NzeUlZVxf5aEtA16vLXzLNbsToUoAiGejnhrVjT3tcDwuamorUdFbUPjox7ljf+98rmK2gZU1Bn+W17bgEA3Df42JhzDwzylfgvQ6UXcuPo3nM6rwN9Gh5tWh3qKwoo6TH5rNy5V12Pxdb3xWGOSmFpYiZv+/TuqtTo8Eh+Jh+L7ShwpEdmTtb+m4aWtpzAi3BPDQj3w312p+OvIULwwY5DUoRH1WJ3JDbgsQFZLpZDhiSlRmBDpg6WfHUFmSTXueG8fllzXB3+/vg8UVtiBrr0qautRVKm9IikyJkkNTZ77c8JkTKTqGjrX6v5IFvDj8TwMC/XAA9f1xnX9fCXbA/XVoWyczvv/9u49uqY77+P45+R2EpGEJHJziSQISqLjEhkVlCHMmEFM6ZgujGkmhKeo3qwqVs3qTLue1nRGY6bToc9TVPUp1U5bM1VJp+pW6loyHDQqQjByIxI5+/kj40xPRV262efE+7XWWXL23jnne7J+fnzyu+wKhQT6adq97Syp4btoEWLXr0d21ZRlO5SX79DATtHqHBuq3GU7dL6mTumJEZrqhZ8LgHf7YUqsfv3efm07eta1OU9bRrKA246RrAYwkuV5yqtrNfftfVr9+XFJUrfWzbRwTDev+4fji+JyLS5w6N3dxbrB+9k2KDjAVyGB/goJ9Pv3w9/1Z+g3jgXb/ZRfWKr/2/6Vav79D2/HmBDl9EvSj1Jib2tora6tU//n8lVSXq0nhnbUr/ol3bb3NttDr3+ut3cWKzEyWD3bhmvlZ8cUERyg9x7qq+hQpigDuP1G532qz778l+v5kgk9NaBjlIUVAd7tZrIBIasBhCzPtXZXsZ5cvUfl1ZfUJMBXT/2os8b0bO3RO9IZhqGtR84qr8Ch/MJS1/GGAlJo0H+eh379nN3fLTCFBvqraaCffG9iM4VT5dV6ZeMRLdtcpMqLlyRJrZoHKTsjUT/t3lpBAbd+cfSiDYf03LpCtWwWpPUP9/PqBdll52s1eGGBTpZfdB179Re91K9DCwurAnAnW7rxiOa984Xref6s/l73S0nAkxCyTELI8mzF5y5o5hs7tfnwWUnSDzpH6zejunrc5gJOp6H1B04pL/+QdhSdkyT52KQfpsTpVxmJ6tIyzNL6yi7U6rXNX2rJxiM6XVl/48qI4ABN7NNWD/Rue8tumnum8qL6PZevyouX9MKYVI28u9UteZ/baUPhKU1csk2SNLl/kh7L9J5NPAA0PqfKq5X2zHoZhuTnY9OBpzO9eoo9YDVClkkIWZ7P6TT0508O67l1haqtMxTZ1K7nfpqiAcnWT4eorXPqnV3FWlzg0D9PVkqqX1/20+6tlJ2RqPgIz/ptYnVtnVZt/0p/+tihY2cvSKofZRvXO16T7kkwfcrb3Lf36tVNX6pLy1Ctzb2n0Wxt/uqnR3X83AU9MiRZ/vxnBoDF7v/TZm06fEaJkcH6aFZ/q8sBvBohyySELO+xr7hM01/fqYOn6sPM+PR4PTGskyXTzy7U1GnltiK9/I8jOn6uPqyE2P308/R4TezTVlEhnr0+51KdU3/dc0J5+Q4dKKmQJAX4+iire0tlZySZsgXw4dJKDX7hY11yGlr+yzR9v13kd35NAMCV3vjsmB59c7d+nBqnF++/2+pyAK9GyDIJIcu7VNfW6bcfHNCSjUclSe2immrhmG63bTreufM1+p9NX2rpp0d1tqp+2l1kU7t+cU9b/bx3vEIDb820u1vFMAzlF5YqL9+hrUfrp2TabNKwLrHK6Zekrq1u/uea87/b9cG+Eg1IbqElE3uZVTIA4BsMw9D6/afUrU0zRXrYdHrA2xCyTELI8k4F/yzVrFW7VFpxUf6+Ns38QbKyMxJvanOI63Gi7IJe+ccRLd9apPM1dZLq7+WVnZGo0d1befVmDpd9dvSsFhc49OH+U65jfdtHanK/JKUnRdzQhiPbvzyrrLxN8rFJ7z+UoeSYkFtRMgAAgKkIWSYhZHmvs1U1euKt3Vq376QkqVdCuJ6/L1Wtmjcx7T0cpZX6Y4FDqz8/rtq6+r8+nWJDNbl/koZ1iWmUi4sLSyq0uMChtbuKVffvvedTW4Vpcv8kDe4cc811VYZhKCvvU+0oOqcxPVrrt6NTbkfZAAAA3xkhyySELO9mGIZWbf9K89fuU1VNnULsfnp6RBeNuLvld3rdXcfOKS/foXVflOjy35q0hHBN7p+kfh1aePQ28mY5dva8/vyPw3p92zHXDZETWwQrJyNJI+5uqQC/hgPm+3tOaPKyHQry91X+I/25fxQAAPAahCyTELIahy/PVGnGyp2u7dN/nBqnp3/S5Ya2JjcMQxsPnVFewSFtPHTGdfwHnaOV0y9J3eObm122VzhdeVGvfnpUr356VOXV9ffaigkN1C/7Juj+Xm0UbPdzXVtzyanBLxTo6Jnz+q9722nm4GSrygYAALhhhCyTELIaj0t1Tr2U79Dv1h9UndNQXFig/vu+bkpPivjW76tzGlq3r0R5+Q7tOV4mqf5eIz/p1lI5/RLVPpr1RJJUefGSVmwp0p8/Oey6GW9YkL/Gf7+tJny/rcKDA1w3xYxsGqD8Rwao6dcCGAAAgKcjZJmEkNX4fF70L81YuVNHz5yXzSZl903UzMEdZPdz35zi4qU6rd5xXH/8+LCOnK6SJAX5+2psr9b6Zd9EtWwWZEX5Hu/ipTqt+fy4Fhf85+cW6O+jsT3baO2uYp2tqtGCEV30897xFlcKAABwYwhZJiFkNU5VFy9pwV+/0IqtxyTVb1bxu7Hd1CE65LpGZHBtdU5Df9tXope+NgIoSUktgrVuekaj3BQEAAA0boQskxCyGre/7SvR42/t0dmqGgX4+ejHqXH6276Sa64twvX7+lq2XcfK9McHuqsPNx4GAABeiJBlEkJW43eqolqPvrlb+YWlrmOJLYKV0y9JI7pdfZc8AAAA3FluJhvwa3rckaJCArVkQk8t21Kk/MJSje7eSoM7R1/zfk8AAADAtTCS1QBGsgAAAABIN5cNmBMFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIn8rC7AExmGIUkqLy+3uBIAAAAAVrqcCS5nhOtByGpARUWFJKl169YWVwIAAADAE1RUVCgsLOy6rrUZNxLJ7hBOp1PFxcUKCQmRzWaztJby8nK1bt1ax44dU2hoqKW1wLvRlmAW2hLMQluCGWhHMMvV2pJhGKqoqFBcXJx8fK5vtRUjWQ3w8fFRq1atrC7DTWhoKB0HTEFbglloSzALbQlmoB3BLA21pesdwbqMjS8AAAAAwESELAAAAAAwESHLw9ntds2dO1d2u93qUuDlaEswC20JZqEtwQy0I5jFzLbExhcAAAAAYCJGsgAAAADARIQsAAAAADARIQsAAAAATETIAgAAAAATEbI83KJFi9S2bVsFBgYqLS1NW7dutbokeJl58+bJZrO5PTp27Gh1WfACH3/8sYYPH664uDjZbDatWbPG7bxhGHrqqacUGxuroKAgDRo0SAcPHrSmWHisa7WjCRMmXNFHZWZmWlMsPNozzzyjnj17KiQkRFFRURoxYoQKCwvdrqmurlZubq4iIiLUtGlTZWVl6eTJkxZVDE90Pe2of//+V/RLOTk5N/Q+hCwPtnLlSs2cOVNz587Vjh07lJqaqiFDhujUqVNWlwYvc9ddd+nEiROuxyeffGJ1SfACVVVVSk1N1aJFixo8/+yzz+rFF1/U4sWLtWXLFgUHB2vIkCGqrq6+zZXCk12rHUlSZmamWx+1YsWK21ghvEVBQYFyc3O1efNm/f3vf1dtba0GDx6sqqoq1zUzZszQO++8o1WrVqmgoEDFxcUaNWqUhVXD01xPO5KkBx980K1fevbZZ2/ofdjC3YOlpaWpZ8+e+sMf/iBJcjqdat26taZNm6bHH3/c4urgLebNm6c1a9Zo586dVpcCL2az2bR69WqNGDFCUv0oVlxcnB5++GHNmjVLklRWVqbo6GgtXbpUY8eOtbBaeKpvtiOpfiTr3LlzV4xwAddSWlqqqKgoFRQUKCMjQ2VlZWrRooWWL1+u0aNHS5IOHDigTp06adOmTerdu7fFFcMTfbMdSfUjWd26ddPChQtv+nUZyfJQNTU12r59uwYNGuQ65uPjo0GDBmnTpk0WVgZvdPDgQcXFxSkxMVHjxo1TUVGR1SXByx05ckQlJSVufVRYWJjS0tLoo3DD8vPzFRUVpeTkZE2ePFlnzpyxuiR4gbKyMklSeHi4JGn79u2qra1165c6duyoNm3a0C/hqr7Zji5btmyZIiMj1aVLFz3xxBM6f/78Db2un2kVwlSnT59WXV2doqOj3Y5HR0frwIEDFlUFb5SWlqalS5cqOTlZJ06c0Pz589W3b1/t3btXISEhVpcHL1VSUiJJDfZRl88B1yMzM1OjRo1SQkKCHA6HZs+eraFDh2rTpk3y9fW1ujx4KKfTqenTp6tPnz7q0qWLpPp+KSAgQM2aNXO7ln4JV9NQO5Kkn/3sZ4qPj1dcXJx2796txx57TIWFhXrrrbeu+7UJWUAjN3ToUNfXKSkpSktLU3x8vN544w1NmjTJwsoAQG5TS7t27aqUlBQlJSUpPz9fAwcOtLAyeLLc3Fzt3buXNcb4Tq7WjrKzs11fd+3aVbGxsRo4cKAcDoeSkpKu67WZLuihIiMj5evre8WOOCdPnlRMTIxFVaExaNasmTp06KBDhw5ZXQq82OV+iD4KZktMTFRkZCR9FK5q6tSpevfdd7Vhwwa1atXKdTwmJkY1NTU6d+6c2/X0S2jI1dpRQ9LS0iTphvolQpaHCggIUPfu3bV+/XrXMafTqfXr1ys9Pd3CyuDtKisr5XA4FBsba3Up8GIJCQmKiYlx66PKy8u1ZcsW+ih8J1999ZXOnDlDH4UrGIahqVOnavXq1froo4+UkJDgdr579+7y9/d365cKCwtVVFREvwSXa7WjhlzePOxG+iWmC3qwmTNnavz48erRo4d69eqlhQsXqqqqShMnTrS6NHiRWbNmafjw4YqPj1dxcbHmzp0rX19f3X///VaXBg9XWVnp9lu7I0eOaOfOnQoPD1ebNm00ffp0LViwQO3bt1dCQoLmzJmjuLg4t53jgG9rR+Hh4Zo/f76ysrIUExMjh8OhRx99VO3atdOQIUMsrBqeKDc3V8uXL9fbb7+tkJAQ1zqrsLAwBQUFKSwsTJMmTdLMmTMVHh6u0NBQTZs2Tenp6ewsCJdrtSOHw6Hly5dr2LBhioiI0O7duzVjxgxlZGQoJSXl+t/IgEf7/e9/b7Rp08YICAgwevXqZWzevNnqkuBlxowZY8TGxhoBAQFGy5YtjTFjxhiHDh2yuix4gQ0bNhiSrniMHz/eMAzDcDqdxpw5c4zo6GjDbrcbAwcONAoLC60tGh7n29rR+fPnjcGDBxstWrQw/P39jfj4eOPBBx80SkpKrC4bHqihdiTJWLJkieuaCxcuGFOmTDGaN29uNGnSxBg5cqRx4sQJ64qGx7lWOyoqKjIyMjKM8PBww263G+3atTMeeeQRo6ys7Ibeh/tkAQAAAICJWJMFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmIiQBQAAAAAmImQBAAAAgIkIWQAAAABgIkIWAAAAAJiIkAUAgMlsNpvWrFljdRkAAIsQsgAAjcqECRNks9mueGRmZlpdGgDgDuFndQEAAJgtMzNTS5YscTtmt9stqgYAcKdhJAsA0OjY7XbFxMS4PZo3by6pfipfXl6ehg4dqqCgICUmJurNN990+/49e/bo3nvvVVBQkCIiIpSdna3Kykq3a/7yl7/orrvukt1uV2xsrKZOnep2/vTp0xo5cqSaNGmi9u3ba+3atbf2QwMAPAYhCwBwx5kzZ46ysrK0a9cujRs3TmPHjtX+/fslSVVVVRoyZIiaN2+ubdu2adWqVfrwww/dQlReXp5yc3OVnZ2tPXv2aO3atWrXrp3be8yfP1/33Xefdu/erWHDhmncuHE6e/bsbf2cAABr2AzDMKwuAgAAs0yYMEGvvfaaAgMD3Y7Pnj1bs2fPls1mU05OjvLy8lznevfure9973t66aWX9PLLL+uxxx7TsWPHFBwcLEl67733NHz4cBUXFys6OlotW7bUxIkTtWDBggZrsNlsevLJJ/X0009Lqg9uTZs21fvvv8/aMAC4A7AmCwDQ6AwYMMAtRElSeHi46+v09HS3c+np6dq5c6ckaf/+/UpNTXUFLEnq06ePnE6nCgsLZbPZVFxcrIEDB35rDSkpKa6vg4ODFRoaqlOnTt3sRwIAeBFCFgCg0QkODr5i+p5ZgoKCrus6f39/t+c2m01Op/NWlAQA8DCsyQIA3HE2b958xfNOnTpJkjp16qRdu3apqqrKdX7jxo3y8fFRcnKyQkJC1LZtW61fv/621gwA8B6MZAEAGp2LFy+qpKTE7Zifn58iIyMlSatWrVKPHj10zz33aNmyZdq6dateeeUVSdK4ceM0d+5cjR8/XvPmzVNpaammTZumBx54QNHR0ZKkefPmKScnR1FRURo6dKgqKiq0ceNGTZs27fZ+UACARyJkAQAanQ8++ECxsbFux5KTk3XgwAFJ9Tv/vf7665oyZYpiY2O1YsUKde7cWZLUpEkTrVu3Tg899JB69uypJk2aKCsrS88//7zrtcaPH6/q6mq98MILmjVrliIjIzV69Ojb9wEBAB6N3QUBAHcUm82m1atXa8SIEVaXAgBopFiTBQAAAAAmImQBAAAAgIlYkwUAuKMwSx4AcKsxkgUAAAAAJiJkAQAAAICJCFkAAAAAYCJCFgAAAACYiJAFAAAAACYiZAEAAACAiQhZAAAAAGAiQhYAAAAAmOj/AXFzHCOzJJAMAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(converg_vals[0]['train'], label='Training loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PF1ENRWQyp7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = losses['train']\n",
        "# Extracting only the loss values from the training data\n",
        "loss_values = [x[0] for x in training_data]\n",
        "\n",
        "# Generating epoch or iteration numbers based on the length of training data\n",
        "epochs = range(1, len(training_data)+1)\n",
        "\n",
        "# Specifying the labels for each metric\n",
        "labels = ['Total Loss', 'Survival Loss', 'Genetic Recovery Loss', 'Graph Recovery Loss', 'Similarity Loss','L2 Loss']\n",
        "\n",
        "# Extracting each set of metrics and plotting them\n",
        "for i in range(len(training_data[0])-1):\n",
        "    metric_values = [x[i] for x in training_data]\n",
        "    plt.plot(epochs, metric_values, label=labels[i])\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Training losses Over Time')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PBMkgGyxVa5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WgXJ_PlWzpW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}